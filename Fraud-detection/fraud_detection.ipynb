{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deep-Dhaduk/AutoGluon/blob/main/Fraud-detection/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLOYOO10iA2h",
        "outputId": "33237938-40eb-4669-b950-8cf4459849ba"
      },
      "id": "dLOYOO10iA2h",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', 200)"
      ],
      "metadata": {
        "id": "Oyd7hRnAmnOh"
      },
      "id": "Oyd7hRnAmnOh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FFNUZSXiGM",
        "outputId": "d7b53885-9a49-4a19-e708-dcf7c74864c3"
      },
      "id": "r4FFNUZSXiGM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m152.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m164.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '/content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "KLaNxkUWXfTA"
      },
      "id": "KLaNxkUWXfTA",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "Xj-iOEArZ6iQ"
      },
      "id": "Xj-iOEArZ6iQ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['isFraud'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DvvGLdMgxZqR",
        "outputId": "81d146a8-ba64-49ce-da86-5fb1f0c1d1e3"
      },
      "id": "DvvGLdMgxZqR",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isFraud\n",
              "0    569877\n",
              "1     20663\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>569877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, temp_data = train_test_split(train_data, test_size=0.2, random_state=42,stratify=train_data['isFraud'])\n",
        "test_data, val_data = train_test_split(temp_data, test_size=0.5, random_state=42,stratify=temp_data['isFraud'])"
      ],
      "metadata": {
        "id": "PkN7w2qMl6Tj"
      },
      "id": "PkN7w2qMl6Tj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "feunXiRHmF2U",
        "outputId": "37794575-8ac5-4599-9c5b-e38d56473d07"
      },
      "id": "feunXiRHmF2U",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
              "40809         3027809        0        1008491          100.00         R   \n",
              "285886        3272886        0        7008212           29.99         W   \n",
              "104256        3091256        0        2071522          107.95         W   \n",
              "507860        3494860        0       13299752          241.95         W   \n",
              "196382        3183382        0        4412283          117.00         W   \n",
              "\n",
              "        card1  card2  card3             card4  card5   card6  addr1  addr2  \\\n",
              "40809    6177  399.0  150.0  american express  150.0  credit  264.0   87.0   \n",
              "285886   7900  345.0  150.0        mastercard  224.0   debit  143.0   87.0   \n",
              "104256  11690  111.0  150.0              visa  226.0  credit  191.0   87.0   \n",
              "507860   2616  327.0  150.0          discover  102.0  credit  330.0   87.0   \n",
              "196382  13780  298.0  150.0              visa  226.0   debit  441.0   87.0   \n",
              "\n",
              "        dist1  dist2  P_emaildomain  R_emaildomain   C1   C2   C3   C4   C5  \\\n",
              "40809     NaN    1.0  anonymous.com  anonymous.com  1.0  1.0  0.0  2.0  0.0   \n",
              "285886    4.0    NaN      gmail.com            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "104256    NaN    NaN    comcast.net            NaN  1.0  1.0  0.0  0.0  1.0   \n",
              "507860    3.0    NaN            NaN            NaN  1.0  2.0  0.0  0.0  1.0   \n",
              "196382    5.0    NaN            NaN            NaN  1.0  1.0  0.0  0.0  0.0   \n",
              "\n",
              "         C6   C7   C8   C9  C10  C11  C12   C13  C14     D1     D2    D3  \\\n",
              "40809   1.0  0.0  2.0  0.0  2.0  1.0  0.0   2.0  1.0  609.0  609.0   NaN   \n",
              "285886  1.0  0.0  0.0  1.0  0.0  1.0  0.0   0.0  0.0    0.0    NaN   NaN   \n",
              "104256  1.0  0.0  0.0  1.0  0.0  1.0  0.0  15.0  1.0  501.0  501.0  18.0   \n",
              "507860  1.0  0.0  0.0  1.0  0.0  1.0  0.0   4.0  1.0  177.0  177.0  86.0   \n",
              "196382  0.0  0.0  0.0  1.0  0.0  1.0  0.0   2.0  1.0    0.0    0.0   0.0   \n",
              "\n",
              "           D4    D5  D6  D7          D8        D9    D10    D11  D12  D13  \\\n",
              "40809     NaN   NaN NaN NaN  609.666687  0.666666    NaN    NaN  NaN  NaN   \n",
              "285886    0.0   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "104256  502.0  18.0 NaN NaN         NaN       NaN  502.0    NaN  NaN  NaN   \n",
              "507860    NaN   NaN NaN NaN         NaN       NaN  177.0  177.0  NaN  NaN   \n",
              "196382    NaN   NaN NaN NaN         NaN       NaN    0.0    0.0  NaN  NaN   \n",
              "\n",
              "        D14    D15   M1   M2   M3   M4   M5   M6   M7   M8   M9   V1   V2  \\\n",
              "40809   NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  NaN    0.0    T    T    T   M0    T    F    F    F    T  1.0  1.0   \n",
              "104256  NaN  502.0  NaN  NaN  NaN  NaN  NaN    T  NaN  NaN  NaN  NaN  NaN   \n",
              "507860  NaN  177.0    T    T    F  NaN  NaN    T    F    F    T  1.0  1.0   \n",
              "196382  NaN    0.0    T    T    T   M0    T    F  NaN  NaN  NaN  1.0  1.0   \n",
              "\n",
              "         V3   V4   V5   V6   V7   V8   V9  V10  V11  V12  V13  V14  V15  V16  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "104256  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  1.0  1.0  0.0  0.0   \n",
              "507860  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
              "196382  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
              "\n",
              "        V17  V18  V19  V20  V21  V22  V23  V24  V25  V26  V27  V28  V29  V30  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "104256  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  1.0   \n",
              "196382  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "        V31  V32  V33  V34  V35  V36  V37  V38  V39  V40  V41  V42  V43  V44  \\\n",
              "40809   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "285886  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "104256  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
              "507860  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "196382  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
              "\n",
              "        V45  ...  V280  V281  V282  V283  V284  V285  V286  V287  V288  V289  \\\n",
              "40809   NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886  1.0  ...   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256  1.0  ...   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   \n",
              "507860  NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  NaN  ...   1.0   1.0   2.0   2.0   1.0   1.0   1.0   1.0   1.0   1.0   \n",
              "\n",
              "        V290  V291  V292  V293  V294  V295  V296  V297  V298  V299  V300  \\\n",
              "40809    1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382   1.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V301  V302  V303  V304  V305   V306   V307   V308   V309   V310  \\\n",
              "40809    0.0   1.0   1.0   1.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "285886   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "104256   0.0   0.0   0.0   0.0   1.0    0.0  200.0    0.0    0.0  200.0   \n",
              "507860   0.0   0.0   0.0   0.0   1.0    0.0    0.0    0.0    0.0    0.0   \n",
              "196382   0.0   0.0   0.0   0.0   1.0  117.0  117.0  117.0  117.0  117.0   \n",
              "\n",
              "         V311   V312   V313   V314   V315  V316  V317  V318  V319  V320  V321  \\\n",
              "40809     0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "104256    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "507860    0.0    0.0    0.0    0.0    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196382  117.0  117.0  117.0  117.0  117.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "        V322  V323  V324  V325  V326  V327  V328  V329  V330  V331  V332  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
              "\n",
              "        V333  V334  V335  V336  V337  V338  V339  id_01    id_02  id_03  \\\n",
              "40809    0.0   0.0   0.0   0.0   0.0   0.0   0.0   -5.0  58410.0    0.0   \n",
              "285886   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "104256   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "507860   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "196382   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN      NaN    NaN   \n",
              "\n",
              "        id_04  id_05  id_06  id_07  id_08  id_09  id_10  id_11     id_12  \\\n",
              "40809     0.0    0.0    0.0    NaN    NaN    0.0    0.0  100.0  NotFound   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN   \n",
              "\n",
              "        id_13  id_14  id_15  id_16  id_17  id_18  id_19  id_20  id_21  id_22  \\\n",
              "40809    52.0 -360.0  Found  Found  166.0    NaN  300.0  214.0    NaN    NaN   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "        id_23  id_24  id_25  id_26  id_27  id_28  id_29      id_30  \\\n",
              "40809     NaN    NaN    NaN    NaN    NaN  Found  Found  Windows 7   \n",
              "285886    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "104256    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "507860    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "196382    NaN    NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
              "\n",
              "                      id_31  id_32      id_33           id_34  id_35  id_36  \\\n",
              "40809   ie 11.0 for desktop   24.0  1920x1080  match_status:2      T      F   \n",
              "285886                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "104256                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "507860                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "196382                  NaN    NaN        NaN             NaN    NaN    NaN   \n",
              "\n",
              "        id_37  id_38  DeviceType   DeviceInfo  \n",
              "40809       T      T     desktop  Trident/7.0  \n",
              "285886    NaN    NaN         NaN          NaN  \n",
              "104256    NaN    NaN         NaN          NaN  \n",
              "507860    NaN    NaN         NaN          NaN  \n",
              "196382    NaN    NaN         NaN          NaN  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1306f74d-c271-475a-893a-91cc8d3bc1a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>card6</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>P_emaildomain</th>\n",
              "      <th>R_emaildomain</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>M1</th>\n",
              "      <th>M2</th>\n",
              "      <th>M3</th>\n",
              "      <th>M4</th>\n",
              "      <th>M5</th>\n",
              "      <th>M6</th>\n",
              "      <th>M7</th>\n",
              "      <th>M8</th>\n",
              "      <th>M9</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>...</th>\n",
              "      <th>V280</th>\n",
              "      <th>V281</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_12</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_15</th>\n",
              "      <th>id_16</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_23</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_27</th>\n",
              "      <th>id_28</th>\n",
              "      <th>id_29</th>\n",
              "      <th>id_30</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40809</th>\n",
              "      <td>3027809</td>\n",
              "      <td>0</td>\n",
              "      <td>1008491</td>\n",
              "      <td>100.00</td>\n",
              "      <td>R</td>\n",
              "      <td>6177</td>\n",
              "      <td>399.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>american express</td>\n",
              "      <td>150.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>264.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>anonymous.com</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>609.666687</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>58410.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NotFound</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-360.0</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>166.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>300.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Found</td>\n",
              "      <td>Found</td>\n",
              "      <td>Windows 7</td>\n",
              "      <td>ie 11.0 for desktop</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1920x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>desktop</td>\n",
              "      <td>Trident/7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285886</th>\n",
              "      <td>3272886</td>\n",
              "      <td>0</td>\n",
              "      <td>7008212</td>\n",
              "      <td>29.99</td>\n",
              "      <td>W</td>\n",
              "      <td>7900</td>\n",
              "      <td>345.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>224.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>143.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gmail.com</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104256</th>\n",
              "      <td>3091256</td>\n",
              "      <td>0</td>\n",
              "      <td>2071522</td>\n",
              "      <td>107.95</td>\n",
              "      <td>W</td>\n",
              "      <td>11690</td>\n",
              "      <td>111.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>191.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>comcast.net</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>501.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>502.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507860</th>\n",
              "      <td>3494860</td>\n",
              "      <td>0</td>\n",
              "      <td>13299752</td>\n",
              "      <td>241.95</td>\n",
              "      <td>W</td>\n",
              "      <td>2616</td>\n",
              "      <td>327.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>102.0</td>\n",
              "      <td>credit</td>\n",
              "      <td>330.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>177.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196382</th>\n",
              "      <td>3183382</td>\n",
              "      <td>0</td>\n",
              "      <td>4412283</td>\n",
              "      <td>117.00</td>\n",
              "      <td>W</td>\n",
              "      <td>13780</td>\n",
              "      <td>298.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>226.0</td>\n",
              "      <td>debit</td>\n",
              "      <td>441.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>M0</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1306f74d-c271-475a-893a-91cc8d3bc1a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1306f74d-c271-475a-893a-91cc8d3bc1a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1306f74d-c271-475a-893a-91cc8d3bc1a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-32405891-3892-4f93-be7e-55cde9c1fa30\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32405891-3892-4f93-be7e-55cde9c1fa30')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-32405891-3892-4f93-be7e-55cde9c1fa30 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELMPJ2u6m3pH",
        "outputId": "34f8d9c5-0227-41a7-926d-8cb7cd72b268"
      },
      "id": "ELMPJ2u6m3pH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(472432, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01MxaCIRm5jY",
        "outputId": "2ceec5d8-7ffc-4d6b-baa9-3358500b99d9"
      },
      "id": "01MxaCIRm5jY",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 472432 entries, 40809 to 337290\n",
            "Columns: 434 entries, TransactionID to DeviceInfo\n",
            "dtypes: float64(399), int64(4), object(31)\n",
            "memory usage: 1.5+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Gm1betSrbGnG",
        "outputId": "273d6344-1045-4df7-e6d6-d43528a25b0e"
      },
      "id": "Gm1betSrbGnG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       TransactionID        isFraud  TransactionDT  TransactionAmt  \\\n",
              "count   4.724320e+05  472432.000000   4.724320e+05   472432.000000   \n",
              "mean    3.282316e+06       0.034989   7.373394e+06      135.071756   \n",
              "std     1.704469e+05       0.183753   4.616510e+06      241.371497   \n",
              "min     2.987000e+06       0.000000   8.640000e+04        0.251000   \n",
              "25%     3.134756e+06       0.000000   3.028537e+06       43.140000   \n",
              "50%     3.282400e+06       0.000000   7.309639e+06       68.911000   \n",
              "75%     3.429918e+06       0.000000   1.124764e+07      125.000000   \n",
              "max     3.577539e+06       1.000000   1.581113e+07    31937.391000   \n",
              "\n",
              "               card1          card2          card3         card5  \\\n",
              "count  472432.000000  465285.000000  471197.000000  469035.00000   \n",
              "mean     9903.027720     362.527137     153.203514     199.30153   \n",
              "std      4902.685441     157.783396      11.353198      41.21739   \n",
              "min      1001.000000     100.000000     100.000000     100.00000   \n",
              "25%      6019.000000     214.000000     150.000000     166.00000   \n",
              "50%      9689.000000     361.000000     150.000000     226.00000   \n",
              "75%     14203.000000     512.000000     150.000000     226.00000   \n",
              "max     18396.000000     600.000000     231.000000     237.00000   \n",
              "\n",
              "               addr1          addr2          dist1         dist2  \\\n",
              "count  419709.000000  419709.000000  190428.000000  30156.000000   \n",
              "mean      290.762967      86.799525     118.583764    231.967933   \n",
              "std       101.785679       2.709423     371.935971    530.961675   \n",
              "min       100.000000      10.000000       0.000000      0.000000   \n",
              "25%       204.000000      87.000000       3.000000      7.000000   \n",
              "50%       299.000000      87.000000       8.000000     38.000000   \n",
              "75%       330.000000      87.000000      24.000000    207.000000   \n",
              "max       540.000000     102.000000   10286.000000  11623.000000   \n",
              "\n",
              "                  C1             C2             C3             C4  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean       14.032987      15.208627       0.005542       4.070306   \n",
              "std       132.403910     153.286836       0.141592      68.312944   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000       0.000000   \n",
              "50%         1.000000       1.000000       0.000000       0.000000   \n",
              "75%         3.000000       3.000000       0.000000       0.000000   \n",
              "max      4685.000000    5691.000000      26.000000    2253.000000   \n",
              "\n",
              "                  C5             C6             C7             C8  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean        5.552901       9.037030       2.822131       5.110992   \n",
              "std        25.731393      70.983085      61.099606      94.517683   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       0.000000       0.000000   \n",
              "50%         0.000000       1.000000       0.000000       0.000000   \n",
              "75%         1.000000       2.000000       0.000000       0.000000   \n",
              "max       349.000000    2253.000000    2255.000000    3331.000000   \n",
              "\n",
              "                  C9            C10            C11            C12  \\\n",
              "count  472432.000000  472432.000000  472432.000000  472432.000000   \n",
              "mean        4.467680       5.204834      10.198232       4.040867   \n",
              "std        16.637458      94.760417      93.546109      85.789475   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       1.000000       0.000000   \n",
              "50%         1.000000       0.000000       1.000000       0.000000   \n",
              "75%         2.000000       0.000000       2.000000       0.000000   \n",
              "max       210.000000    3257.000000    3188.000000    3188.000000   \n",
              "\n",
              "                 C13            C14             D1             D2  \\\n",
              "count  472432.000000  472432.000000  471398.000000  247635.000000   \n",
              "mean       32.418708       8.266002      94.290778     169.547641   \n",
              "std       128.712688      49.233935     157.580267     177.240248   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000      26.000000   \n",
              "50%         3.000000       1.000000       3.000000      97.000000   \n",
              "75%        12.000000       2.000000     122.000000     276.000000   \n",
              "max      2918.000000    1429.000000     640.000000     640.000000   \n",
              "\n",
              "                  D3             D4             D5            D6  \\\n",
              "count  261839.000000  337134.000000  224193.000000  58756.000000   \n",
              "mean       28.292470     139.916333      42.325206     69.584553   \n",
              "std        62.242703     191.026108      89.022043    143.456867   \n",
              "min         0.000000    -122.000000       0.000000    -83.000000   \n",
              "25%         1.000000       0.000000       1.000000      0.000000   \n",
              "50%         8.000000      26.000000      10.000000      0.000000   \n",
              "75%        27.000000     253.000000      32.000000     39.000000   \n",
              "max       819.000000     864.000000     819.000000    873.000000   \n",
              "\n",
              "                 D7            D8            D9            D10            D11  \\\n",
              "count  31179.000000  60129.000000  60129.000000  411587.000000  248762.000000   \n",
              "mean      41.567369    146.037489      0.560664     124.141052     146.878374   \n",
              "std       99.928586    231.821386      0.316786     182.744118     186.155725   \n",
              "min        0.000000      0.000000      0.000000       0.000000     -33.000000   \n",
              "25%        0.000000      0.958333      0.208333       0.000000       0.000000   \n",
              "50%        0.000000     37.916664      0.666666      15.000000      43.000000   \n",
              "75%       17.000000    187.291672      0.833333     198.000000     275.000000   \n",
              "max      843.000000   1707.791626      0.958333     876.000000     670.000000   \n",
              "\n",
              "                D12           D13           D14            D15             V1  \\\n",
              "count  51953.000000  49740.000000  49944.000000  401062.000000  248762.000000   \n",
              "mean      53.991974     17.651488     57.590261     163.775763       0.999944   \n",
              "std      124.102784     67.093694    135.987939     202.729060       0.007502   \n",
              "min      -83.000000      0.000000   -193.000000     -83.000000       0.000000   \n",
              "25%        0.000000      0.000000      0.000000       0.000000       1.000000   \n",
              "50%        0.000000      0.000000      0.000000      52.000000       1.000000   \n",
              "75%       12.000000      0.000000      2.000000     314.000000       1.000000   \n",
              "max      648.000000    847.000000    878.000000     879.000000       1.000000   \n",
              "\n",
              "                  V2             V3             V4             V5  \\\n",
              "count  248762.000000  248762.000000  248762.000000  248762.000000   \n",
              "mean        1.045276       1.078320       0.846214       0.876866   \n",
              "std         0.240037       0.321103       0.439820       0.475907   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       1.000000       1.000000   \n",
              "50%         1.000000       1.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         8.000000       9.000000       6.000000       6.000000   \n",
              "\n",
              "                  V6             V7             V8             V9  \\\n",
              "count  248762.000000  248762.000000  248762.000000  248762.000000   \n",
              "mean        1.045980       1.073070       1.027830       1.041666   \n",
              "std         0.239543       0.304999       0.186218       0.226492   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       1.000000       1.000000   \n",
              "50%         1.000000       1.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         9.000000       9.000000       8.000000       8.000000   \n",
              "\n",
              "                 V10            V11            V12            V13  \\\n",
              "count  248762.000000  248762.000000  411548.000000  411548.000000   \n",
              "mean        0.463065       0.478023       0.559568       0.598674   \n",
              "std         0.521544       0.552247       0.510389       0.531891   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       1.000000       1.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         4.000000       5.000000       3.000000       6.000000   \n",
              "\n",
              "                 V14            V15            V16            V17  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.999478       0.122792       0.123852       0.134553   \n",
              "std         0.022851       0.332787       0.342085       0.364560   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       7.000000      15.000000      15.000000   \n",
              "\n",
              "                 V18            V19            V20            V21  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.135870       0.815878       0.847269       0.130274   \n",
              "std         0.371654       0.425479       0.458769       0.339752   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       0.000000   \n",
              "50%         0.000000       1.000000       1.000000       0.000000   \n",
              "75%         0.000000       1.000000       1.000000       0.000000   \n",
              "max        15.000000       7.000000      15.000000       5.000000   \n",
              "\n",
              "                 V22            V23            V24            V25  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.132857       1.034742       1.057979       0.977619   \n",
              "std         0.359792       0.248966       0.306040       0.185509   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max         8.000000      13.000000      13.000000       7.000000   \n",
              "\n",
              "                 V26            V27            V28            V29  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.987817       0.000787       0.000843       0.386895   \n",
              "std         0.207378       0.028901       0.031436       0.510507   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       1.000000   \n",
              "max        13.000000       4.000000       4.000000       5.000000   \n",
              "\n",
              "                 V30            V31            V32            V33  \\\n",
              "count  411548.000000  411548.000000  411548.000000  411548.000000   \n",
              "mean        0.405326       0.141369       0.142977       0.131105   \n",
              "std         0.553574       0.356318       0.367834       0.341203   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max         9.000000       7.000000      15.000000       7.000000   \n",
              "\n",
              "                 V34            V35            V36            V37  \\\n",
              "count  411548.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        0.139476       0.542442       0.579028       1.108097   \n",
              "std         0.356876       0.516015       0.539235       0.693882   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max        13.000000       3.000000       5.000000      54.000000   \n",
              "\n",
              "                 V38            V39            V40            V41  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        1.162535       0.166881       0.177908       0.999235   \n",
              "std         0.862675       0.453426       0.506937       0.027655   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       1.000000   \n",
              "50%         1.000000       0.000000       0.000000       1.000000   \n",
              "75%         1.000000       0.000000       0.000000       1.000000   \n",
              "max        54.000000      15.000000      24.000000       1.000000   \n",
              "\n",
              "                 V42            V43            V44            V45  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        0.156958       0.169797       1.084225       1.121117   \n",
              "std         0.383964       0.434360       0.647636       0.738306   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       1.000000       1.000000   \n",
              "50%         0.000000       0.000000       1.000000       1.000000   \n",
              "75%         0.000000       0.000000       1.000000       1.000000   \n",
              "max         8.000000       8.000000      48.000000      48.000000   \n",
              "\n",
              "                 V46            V47            V48            V49  \\\n",
              "count  337096.000000  337096.000000  337096.000000  337096.000000   \n",
              "mean        1.022237       1.038485       0.382099       0.396753   \n",
              "std         0.166645       0.231641       0.507784       0.542471   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       1.000000       0.000000       0.000000   \n",
              "50%         1.000000       1.000000       0.000000       0.000000   \n",
              "75%         1.000000       1.000000       1.000000       1.000000   \n",
              "max         6.000000      12.000000       5.000000       5.000000   \n",
              "\n",
              "                 V50            V51            V52            V53  \\\n",
              "count  337096.000000  337096.000000  337096.000000  410643.000000   \n",
              "mean        0.165490       0.171094       0.183206       0.576839   \n",
              "std         0.374739       0.404220       0.439467       0.511402   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       1.000000   \n",
              "75%         0.000000       0.000000       0.000000       1.000000   \n",
              "max         5.000000       6.000000      12.000000       5.000000   \n",
              "\n",
              "                 V54            V55            V56            V57  \\\n",
              "count  410643.000000  410643.000000  410643.000000  410643.000000   \n",
              "mean        0.619433       1.067879       1.121604       0.128761   \n",
              "std         0.534515       0.394029       0.674774       0.349482   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       1.000000       1.000000       0.000000   \n",
              "50%         1.000000       1.000000       1.000000       0.000000   \n",
              "75%         1.000000       1.000000       1.000000       0.000000   \n",
              "max         6.000000      17.000000      51.000000       6.000000   \n",
              "\n",
              "                 V58            V59  ...           V263           V264  \\\n",
              "count  410643.000000  410643.000000  ...  104634.000000  104634.000000   \n",
              "mean        0.133050       0.135025  ...     115.331141     197.024192   \n",
              "std         0.374611       0.380377  ...    1304.395428    2251.429647   \n",
              "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "75%         0.000000       0.000000  ...       0.000000      33.835201   \n",
              "max        10.000000      16.000000  ...  153600.000000  153600.000000   \n",
              "\n",
              "                V265           V266           V267           V268  \\\n",
              "count  104634.000000  104634.000000  104634.000000  104634.000000   \n",
              "mean      150.524102       9.419733      35.853965      18.750623   \n",
              "std      1596.621628     225.991041     638.130103     318.872244   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%        21.200001       0.000000       0.000000       0.000000   \n",
              "max    153600.000000   55125.000000   55125.000000   55125.000000   \n",
              "\n",
              "                V269           V270           V271           V272  \\\n",
              "count  104634.000000  113426.000000  113426.000000  113426.000000   \n",
              "mean        6.215661       7.837482       9.618513       8.619011   \n",
              "std       225.304837      66.283284      75.350497      70.841693   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max     55125.000000    4000.000000    4000.000000    4000.000000   \n",
              "\n",
              "                V273           V274           V275           V276  \\\n",
              "count  104634.000000  104634.000000  104634.000000  104634.000000   \n",
              "mean       71.711838     104.055281      86.369361      31.286498   \n",
              "std       912.198953    1233.851264    1048.212356     634.164242   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max     51200.000000   66000.000000   51200.000000  104060.000000   \n",
              "\n",
              "                V277           V278           V279           V280  \\\n",
              "count  104634.000000  104634.000000  472424.000000  472424.000000   \n",
              "mean       51.056396      41.795056       1.118349       1.962747   \n",
              "std       747.043020     680.276486      20.934257      27.790722   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       1.000000   \n",
              "max    104060.000000  104060.000000     879.000000     975.000000   \n",
              "\n",
              "                V281           V282           V283           V284  \\\n",
              "count  471398.000000  471398.000000  471398.000000  472424.000000   \n",
              "mean        0.087794       0.817163       0.991044       0.088577   \n",
              "std         0.513986       0.923735       1.568529       0.338419   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       1.000000       1.000000       0.000000   \n",
              "75%         0.000000       1.000000       1.000000       0.000000   \n",
              "max        22.000000      32.000000      68.000000      12.000000   \n",
              "\n",
              "                V285           V286           V287           V288  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        1.163580       0.031705       0.357973       0.184074   \n",
              "std         3.257427       0.191634       1.076463       0.430966   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000       0.000000       0.000000   \n",
              "max        95.000000       8.000000      31.000000      10.000000   \n",
              "\n",
              "                V289           V290           V291           V292  \\\n",
              "count  471398.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        0.235285       1.104112       1.670154       1.243121   \n",
              "std         0.598261       0.790309      16.579363       3.868017   \n",
              "min         0.000000       1.000000       1.000000       1.000000   \n",
              "25%         0.000000       1.000000       1.000000       1.000000   \n",
              "50%         0.000000       1.000000       1.000000       1.000000   \n",
              "75%         0.000000       1.000000       1.000000       1.000000   \n",
              "max        12.000000      67.000000    1055.000000     323.000000   \n",
              "\n",
              "                V293           V294           V295           V296  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        0.937903       2.318648       1.430361       0.327358   \n",
              "std        20.503040      39.608404      25.906506       3.255640   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max       868.000000    1286.000000     928.000000      93.000000   \n",
              "\n",
              "                V297           V298           V299           V300  \\\n",
              "count  472424.000000  472424.000000  472424.000000  471398.000000   \n",
              "mean        0.088897       0.297574       0.170906       0.045117   \n",
              "std         0.626812       3.168491       1.719834       0.289040   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max        12.000000      93.000000      49.000000      11.000000   \n",
              "\n",
              "                V301           V302           V303           V304  \\\n",
              "count  471398.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        0.051557       0.252483       0.283709       0.264781   \n",
              "std         0.317049       0.482676       0.624290       0.528128   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max        13.000000      16.000000      20.000000      16.000000   \n",
              "\n",
              "                V305           V306           V307           V308  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean        1.000004     139.185746     408.585703     229.801314   \n",
              "std         0.002058    2340.366681    4394.257176    3015.639763   \n",
              "min         1.000000       0.000000       0.000000       0.000000   \n",
              "25%         1.000000       0.000000       0.000000       0.000000   \n",
              "50%         1.000000       0.000000       0.000000       0.000000   \n",
              "75%         1.000000       0.000000     151.000000      36.374399   \n",
              "max         2.000000  108800.000000  145765.000000  108800.000000   \n",
              "\n",
              "                V309           V310           V311           V312  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean       11.043251     118.096039       4.299015      39.261609   \n",
              "std       123.164461     355.508258     111.391074     177.550832   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000     107.949997       0.000000       0.000000   \n",
              "max     55125.000000   55125.000000   55125.000000   55125.000000   \n",
              "\n",
              "                V313           V314           V315           V316  \\\n",
              "count  471398.000000  471398.000000  471398.000000  472424.000000   \n",
              "mean       21.391813      43.172440      26.792160     109.272638   \n",
              "std        96.323808     173.127457     116.922643    2260.182139   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max      4817.470215    7519.870117    4817.470215   93630.000000   \n",
              "\n",
              "                V317           V318           V319           V320  \\\n",
              "count  472424.000000  472424.000000  472424.000000  472424.000000   \n",
              "mean      247.806641     161.608498      18.242533      41.854071   \n",
              "std      3983.003265    2786.397337     333.129270     474.271828   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max    134021.000000   98476.000000  104060.000000  104060.000000   \n",
              "\n",
              "                V321          V322          V323          V324          V325  \\\n",
              "count  472424.000000  65995.000000  65995.000000  65995.000000  65995.000000   \n",
              "mean       28.154157      6.172346     13.021971      9.118206      0.058626   \n",
              "std       383.439267     55.743839    106.467772     73.374424      0.303183   \n",
              "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%         0.000000      0.000000      1.000000      0.000000      0.000000   \n",
              "max    104060.000000    879.000000   1411.000000    976.000000     12.000000   \n",
              "\n",
              "               V326          V327         V328          V329          V330  \\\n",
              "count  65995.000000  65995.000000  65995.00000  65995.000000  65995.000000   \n",
              "mean       0.843518      0.294553      0.33498      1.302705      0.770649   \n",
              "std        3.929171      1.358688      1.57068      8.743791      4.711790   \n",
              "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
              "max       44.000000     18.000000     15.00000     99.000000     55.000000   \n",
              "\n",
              "                V331           V332           V333          V334  \\\n",
              "count   65995.000000   65995.000000   65995.000000  65995.000000   \n",
              "mean      717.371506    1369.215320    1008.861322     10.173960   \n",
              "std      6197.946391   11147.950514    7937.940219    265.961322   \n",
              "min         0.000000       0.000000       0.000000      0.000000   \n",
              "25%         0.000000       0.000000       0.000000      0.000000   \n",
              "50%         0.000000       0.000000       0.000000      0.000000   \n",
              "75%         0.000000      25.000000       0.000000      0.000000   \n",
              "max    160000.000000  160000.000000  160000.000000  55125.000000   \n",
              "\n",
              "               V335          V336           V337           V338  \\\n",
              "count  65995.000000  65995.000000   65995.000000   65995.000000   \n",
              "mean      59.177881     28.717916      55.487174     150.920290   \n",
              "std      404.746249    294.103054     700.321813    1114.146312   \n",
              "min        0.000000      0.000000       0.000000       0.000000   \n",
              "25%        0.000000      0.000000       0.000000       0.000000   \n",
              "50%        0.000000      0.000000       0.000000       0.000000   \n",
              "75%        0.000000      0.000000       0.000000       0.000000   \n",
              "max    55125.000000  55125.000000  104060.000000  104060.000000   \n",
              "\n",
              "                V339          id_01          id_02         id_03  \\\n",
              "count   65995.000000  115658.000000  112989.000000  53192.000000   \n",
              "mean      100.760998     -10.178682  174752.397685      0.061156   \n",
              "std       841.480465      14.352676  159604.598061      0.597383   \n",
              "min         0.000000    -100.000000      30.000000    -13.000000   \n",
              "25%         0.000000     -10.000000   67963.000000      0.000000   \n",
              "50%         0.000000      -5.000000  125988.000000      0.000000   \n",
              "75%         0.000000      -5.000000  228757.000000      0.000000   \n",
              "max    104060.000000       0.000000  999595.000000      9.000000   \n",
              "\n",
              "              id_04          id_05          id_06        id_07        id_08  \\\n",
              "count  53192.000000  109791.000000  109791.000000  4114.000000  4114.000000   \n",
              "mean      -0.059821       1.612855      -6.687789    13.372387   -38.516529   \n",
              "std        0.709789       5.254521      16.472918    11.410702    26.080732   \n",
              "min      -28.000000     -72.000000    -100.000000   -46.000000  -100.000000   \n",
              "25%        0.000000       0.000000      -6.000000     5.000000   -48.000000   \n",
              "50%        0.000000       0.000000       0.000000    14.000000   -34.000000   \n",
              "75%        0.000000       1.000000       0.000000    22.000000   -23.000000   \n",
              "max        0.000000      52.000000       0.000000    61.000000     0.000000   \n",
              "\n",
              "              id_09         id_10          id_11          id_13         id_14  \\\n",
              "count  60129.000000  60129.000000  113079.000000  102085.000000  64168.000000   \n",
              "mean       0.089557     -0.306425      99.743676      48.070461   -344.615696   \n",
              "std        0.982185      2.888210       1.131255      11.769504     93.435337   \n",
              "min      -36.000000   -100.000000      90.000000      10.000000   -660.000000   \n",
              "25%        0.000000      0.000000     100.000000      49.000000   -360.000000   \n",
              "50%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
              "75%        0.000000      0.000000     100.000000      52.000000   -300.000000   \n",
              "max       17.000000      0.000000     100.000000      64.000000    720.000000   \n",
              "\n",
              "               id_17         id_18          id_19          id_20        id_21  \\\n",
              "count  111801.000000  36124.000000  111759.000000  111713.000000  4119.000000   \n",
              "mean      189.469915     14.239647     352.662408     403.676054   371.726633   \n",
              "std        30.392523      1.573547     141.276876     152.056911   200.853603   \n",
              "min       100.000000     10.000000     100.000000     100.000000   100.000000   \n",
              "25%       166.000000     13.000000     266.000000     256.000000   252.000000   \n",
              "50%       166.000000     15.000000     341.000000     472.000000   252.000000   \n",
              "75%       225.000000     15.000000     427.000000     533.000000   500.000000   \n",
              "max       229.000000     29.000000     671.000000     661.000000   854.000000   \n",
              "\n",
              "             id_22        id_24        id_25        id_26         id_32  \n",
              "count  4126.000000  3793.000000  4102.000000  4122.000000  62203.000000  \n",
              "mean     15.950315    12.792776   328.958313   149.121058     26.516920  \n",
              "std       6.823112     2.346845    97.406803    32.192881      3.739222  \n",
              "min      10.000000    11.000000   100.000000   100.000000      0.000000  \n",
              "25%      14.000000    11.000000   321.000000   119.000000     24.000000  \n",
              "50%      14.000000    11.000000   321.000000   147.000000     24.000000  \n",
              "75%      14.000000    15.000000   366.750000   169.000000     32.000000  \n",
              "max      44.000000    26.000000   548.000000   216.000000     32.000000  \n",
              "\n",
              "[8 rows x 403 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd7ac8e6-c8be-4328-aefa-cb9aa31febe4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card5</th>\n",
              "      <th>addr1</th>\n",
              "      <th>addr2</th>\n",
              "      <th>dist1</th>\n",
              "      <th>dist2</th>\n",
              "      <th>C1</th>\n",
              "      <th>C2</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>C5</th>\n",
              "      <th>C6</th>\n",
              "      <th>C7</th>\n",
              "      <th>C8</th>\n",
              "      <th>C9</th>\n",
              "      <th>C10</th>\n",
              "      <th>C11</th>\n",
              "      <th>C12</th>\n",
              "      <th>C13</th>\n",
              "      <th>C14</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>D15</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>V51</th>\n",
              "      <th>V52</th>\n",
              "      <th>V53</th>\n",
              "      <th>V54</th>\n",
              "      <th>V55</th>\n",
              "      <th>V56</th>\n",
              "      <th>V57</th>\n",
              "      <th>V58</th>\n",
              "      <th>V59</th>\n",
              "      <th>...</th>\n",
              "      <th>V263</th>\n",
              "      <th>V264</th>\n",
              "      <th>V265</th>\n",
              "      <th>V266</th>\n",
              "      <th>V267</th>\n",
              "      <th>V268</th>\n",
              "      <th>V269</th>\n",
              "      <th>V270</th>\n",
              "      <th>V271</th>\n",
              "      <th>V272</th>\n",
              "      <th>V273</th>\n",
              "      <th>V274</th>\n",
              "      <th>V275</th>\n",
              "      <th>V276</th>\n",
              "      <th>V277</th>\n",
              "      <th>V278</th>\n",
              "      <th>V279</th>\n",
              "      <th>V280</th>\n",
              "      <th>V281</th>\n",
              "      <th>V282</th>\n",
              "      <th>V283</th>\n",
              "      <th>V284</th>\n",
              "      <th>V285</th>\n",
              "      <th>V286</th>\n",
              "      <th>V287</th>\n",
              "      <th>V288</th>\n",
              "      <th>V289</th>\n",
              "      <th>V290</th>\n",
              "      <th>V291</th>\n",
              "      <th>V292</th>\n",
              "      <th>V293</th>\n",
              "      <th>V294</th>\n",
              "      <th>V295</th>\n",
              "      <th>V296</th>\n",
              "      <th>V297</th>\n",
              "      <th>V298</th>\n",
              "      <th>V299</th>\n",
              "      <th>V300</th>\n",
              "      <th>V301</th>\n",
              "      <th>V302</th>\n",
              "      <th>V303</th>\n",
              "      <th>V304</th>\n",
              "      <th>V305</th>\n",
              "      <th>V306</th>\n",
              "      <th>V307</th>\n",
              "      <th>V308</th>\n",
              "      <th>V309</th>\n",
              "      <th>V310</th>\n",
              "      <th>V311</th>\n",
              "      <th>V312</th>\n",
              "      <th>V313</th>\n",
              "      <th>V314</th>\n",
              "      <th>V315</th>\n",
              "      <th>V316</th>\n",
              "      <th>V317</th>\n",
              "      <th>V318</th>\n",
              "      <th>V319</th>\n",
              "      <th>V320</th>\n",
              "      <th>V321</th>\n",
              "      <th>V322</th>\n",
              "      <th>V323</th>\n",
              "      <th>V324</th>\n",
              "      <th>V325</th>\n",
              "      <th>V326</th>\n",
              "      <th>V327</th>\n",
              "      <th>V328</th>\n",
              "      <th>V329</th>\n",
              "      <th>V330</th>\n",
              "      <th>V331</th>\n",
              "      <th>V332</th>\n",
              "      <th>V333</th>\n",
              "      <th>V334</th>\n",
              "      <th>V335</th>\n",
              "      <th>V336</th>\n",
              "      <th>V337</th>\n",
              "      <th>V338</th>\n",
              "      <th>V339</th>\n",
              "      <th>id_01</th>\n",
              "      <th>id_02</th>\n",
              "      <th>id_03</th>\n",
              "      <th>id_04</th>\n",
              "      <th>id_05</th>\n",
              "      <th>id_06</th>\n",
              "      <th>id_07</th>\n",
              "      <th>id_08</th>\n",
              "      <th>id_09</th>\n",
              "      <th>id_10</th>\n",
              "      <th>id_11</th>\n",
              "      <th>id_13</th>\n",
              "      <th>id_14</th>\n",
              "      <th>id_17</th>\n",
              "      <th>id_18</th>\n",
              "      <th>id_19</th>\n",
              "      <th>id_20</th>\n",
              "      <th>id_21</th>\n",
              "      <th>id_22</th>\n",
              "      <th>id_24</th>\n",
              "      <th>id_25</th>\n",
              "      <th>id_26</th>\n",
              "      <th>id_32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.724320e+05</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>4.724320e+05</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>465285.000000</td>\n",
              "      <td>471197.000000</td>\n",
              "      <td>469035.00000</td>\n",
              "      <td>419709.000000</td>\n",
              "      <td>419709.000000</td>\n",
              "      <td>190428.000000</td>\n",
              "      <td>30156.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>472432.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>247635.000000</td>\n",
              "      <td>261839.000000</td>\n",
              "      <td>337134.000000</td>\n",
              "      <td>224193.000000</td>\n",
              "      <td>58756.000000</td>\n",
              "      <td>31179.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>411587.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>51953.000000</td>\n",
              "      <td>49740.000000</td>\n",
              "      <td>49944.000000</td>\n",
              "      <td>401062.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>248762.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>411548.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>337096.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>410643.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>113426.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>104634.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>471398.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>472424.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.00000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>65995.000000</td>\n",
              "      <td>115658.000000</td>\n",
              "      <td>112989.000000</td>\n",
              "      <td>53192.000000</td>\n",
              "      <td>53192.000000</td>\n",
              "      <td>109791.000000</td>\n",
              "      <td>109791.000000</td>\n",
              "      <td>4114.000000</td>\n",
              "      <td>4114.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>60129.000000</td>\n",
              "      <td>113079.000000</td>\n",
              "      <td>102085.000000</td>\n",
              "      <td>64168.000000</td>\n",
              "      <td>111801.000000</td>\n",
              "      <td>36124.000000</td>\n",
              "      <td>111759.000000</td>\n",
              "      <td>111713.000000</td>\n",
              "      <td>4119.000000</td>\n",
              "      <td>4126.000000</td>\n",
              "      <td>3793.000000</td>\n",
              "      <td>4102.000000</td>\n",
              "      <td>4122.000000</td>\n",
              "      <td>62203.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.282316e+06</td>\n",
              "      <td>0.034989</td>\n",
              "      <td>7.373394e+06</td>\n",
              "      <td>135.071756</td>\n",
              "      <td>9903.027720</td>\n",
              "      <td>362.527137</td>\n",
              "      <td>153.203514</td>\n",
              "      <td>199.30153</td>\n",
              "      <td>290.762967</td>\n",
              "      <td>86.799525</td>\n",
              "      <td>118.583764</td>\n",
              "      <td>231.967933</td>\n",
              "      <td>14.032987</td>\n",
              "      <td>15.208627</td>\n",
              "      <td>0.005542</td>\n",
              "      <td>4.070306</td>\n",
              "      <td>5.552901</td>\n",
              "      <td>9.037030</td>\n",
              "      <td>2.822131</td>\n",
              "      <td>5.110992</td>\n",
              "      <td>4.467680</td>\n",
              "      <td>5.204834</td>\n",
              "      <td>10.198232</td>\n",
              "      <td>4.040867</td>\n",
              "      <td>32.418708</td>\n",
              "      <td>8.266002</td>\n",
              "      <td>94.290778</td>\n",
              "      <td>169.547641</td>\n",
              "      <td>28.292470</td>\n",
              "      <td>139.916333</td>\n",
              "      <td>42.325206</td>\n",
              "      <td>69.584553</td>\n",
              "      <td>41.567369</td>\n",
              "      <td>146.037489</td>\n",
              "      <td>0.560664</td>\n",
              "      <td>124.141052</td>\n",
              "      <td>146.878374</td>\n",
              "      <td>53.991974</td>\n",
              "      <td>17.651488</td>\n",
              "      <td>57.590261</td>\n",
              "      <td>163.775763</td>\n",
              "      <td>0.999944</td>\n",
              "      <td>1.045276</td>\n",
              "      <td>1.078320</td>\n",
              "      <td>0.846214</td>\n",
              "      <td>0.876866</td>\n",
              "      <td>1.045980</td>\n",
              "      <td>1.073070</td>\n",
              "      <td>1.027830</td>\n",
              "      <td>1.041666</td>\n",
              "      <td>0.463065</td>\n",
              "      <td>0.478023</td>\n",
              "      <td>0.559568</td>\n",
              "      <td>0.598674</td>\n",
              "      <td>0.999478</td>\n",
              "      <td>0.122792</td>\n",
              "      <td>0.123852</td>\n",
              "      <td>0.134553</td>\n",
              "      <td>0.135870</td>\n",
              "      <td>0.815878</td>\n",
              "      <td>0.847269</td>\n",
              "      <td>0.130274</td>\n",
              "      <td>0.132857</td>\n",
              "      <td>1.034742</td>\n",
              "      <td>1.057979</td>\n",
              "      <td>0.977619</td>\n",
              "      <td>0.987817</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>0.386895</td>\n",
              "      <td>0.405326</td>\n",
              "      <td>0.141369</td>\n",
              "      <td>0.142977</td>\n",
              "      <td>0.131105</td>\n",
              "      <td>0.139476</td>\n",
              "      <td>0.542442</td>\n",
              "      <td>0.579028</td>\n",
              "      <td>1.108097</td>\n",
              "      <td>1.162535</td>\n",
              "      <td>0.166881</td>\n",
              "      <td>0.177908</td>\n",
              "      <td>0.999235</td>\n",
              "      <td>0.156958</td>\n",
              "      <td>0.169797</td>\n",
              "      <td>1.084225</td>\n",
              "      <td>1.121117</td>\n",
              "      <td>1.022237</td>\n",
              "      <td>1.038485</td>\n",
              "      <td>0.382099</td>\n",
              "      <td>0.396753</td>\n",
              "      <td>0.165490</td>\n",
              "      <td>0.171094</td>\n",
              "      <td>0.183206</td>\n",
              "      <td>0.576839</td>\n",
              "      <td>0.619433</td>\n",
              "      <td>1.067879</td>\n",
              "      <td>1.121604</td>\n",
              "      <td>0.128761</td>\n",
              "      <td>0.133050</td>\n",
              "      <td>0.135025</td>\n",
              "      <td>...</td>\n",
              "      <td>115.331141</td>\n",
              "      <td>197.024192</td>\n",
              "      <td>150.524102</td>\n",
              "      <td>9.419733</td>\n",
              "      <td>35.853965</td>\n",
              "      <td>18.750623</td>\n",
              "      <td>6.215661</td>\n",
              "      <td>7.837482</td>\n",
              "      <td>9.618513</td>\n",
              "      <td>8.619011</td>\n",
              "      <td>71.711838</td>\n",
              "      <td>104.055281</td>\n",
              "      <td>86.369361</td>\n",
              "      <td>31.286498</td>\n",
              "      <td>51.056396</td>\n",
              "      <td>41.795056</td>\n",
              "      <td>1.118349</td>\n",
              "      <td>1.962747</td>\n",
              "      <td>0.087794</td>\n",
              "      <td>0.817163</td>\n",
              "      <td>0.991044</td>\n",
              "      <td>0.088577</td>\n",
              "      <td>1.163580</td>\n",
              "      <td>0.031705</td>\n",
              "      <td>0.357973</td>\n",
              "      <td>0.184074</td>\n",
              "      <td>0.235285</td>\n",
              "      <td>1.104112</td>\n",
              "      <td>1.670154</td>\n",
              "      <td>1.243121</td>\n",
              "      <td>0.937903</td>\n",
              "      <td>2.318648</td>\n",
              "      <td>1.430361</td>\n",
              "      <td>0.327358</td>\n",
              "      <td>0.088897</td>\n",
              "      <td>0.297574</td>\n",
              "      <td>0.170906</td>\n",
              "      <td>0.045117</td>\n",
              "      <td>0.051557</td>\n",
              "      <td>0.252483</td>\n",
              "      <td>0.283709</td>\n",
              "      <td>0.264781</td>\n",
              "      <td>1.000004</td>\n",
              "      <td>139.185746</td>\n",
              "      <td>408.585703</td>\n",
              "      <td>229.801314</td>\n",
              "      <td>11.043251</td>\n",
              "      <td>118.096039</td>\n",
              "      <td>4.299015</td>\n",
              "      <td>39.261609</td>\n",
              "      <td>21.391813</td>\n",
              "      <td>43.172440</td>\n",
              "      <td>26.792160</td>\n",
              "      <td>109.272638</td>\n",
              "      <td>247.806641</td>\n",
              "      <td>161.608498</td>\n",
              "      <td>18.242533</td>\n",
              "      <td>41.854071</td>\n",
              "      <td>28.154157</td>\n",
              "      <td>6.172346</td>\n",
              "      <td>13.021971</td>\n",
              "      <td>9.118206</td>\n",
              "      <td>0.058626</td>\n",
              "      <td>0.843518</td>\n",
              "      <td>0.294553</td>\n",
              "      <td>0.33498</td>\n",
              "      <td>1.302705</td>\n",
              "      <td>0.770649</td>\n",
              "      <td>717.371506</td>\n",
              "      <td>1369.215320</td>\n",
              "      <td>1008.861322</td>\n",
              "      <td>10.173960</td>\n",
              "      <td>59.177881</td>\n",
              "      <td>28.717916</td>\n",
              "      <td>55.487174</td>\n",
              "      <td>150.920290</td>\n",
              "      <td>100.760998</td>\n",
              "      <td>-10.178682</td>\n",
              "      <td>174752.397685</td>\n",
              "      <td>0.061156</td>\n",
              "      <td>-0.059821</td>\n",
              "      <td>1.612855</td>\n",
              "      <td>-6.687789</td>\n",
              "      <td>13.372387</td>\n",
              "      <td>-38.516529</td>\n",
              "      <td>0.089557</td>\n",
              "      <td>-0.306425</td>\n",
              "      <td>99.743676</td>\n",
              "      <td>48.070461</td>\n",
              "      <td>-344.615696</td>\n",
              "      <td>189.469915</td>\n",
              "      <td>14.239647</td>\n",
              "      <td>352.662408</td>\n",
              "      <td>403.676054</td>\n",
              "      <td>371.726633</td>\n",
              "      <td>15.950315</td>\n",
              "      <td>12.792776</td>\n",
              "      <td>328.958313</td>\n",
              "      <td>149.121058</td>\n",
              "      <td>26.516920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.704469e+05</td>\n",
              "      <td>0.183753</td>\n",
              "      <td>4.616510e+06</td>\n",
              "      <td>241.371497</td>\n",
              "      <td>4902.685441</td>\n",
              "      <td>157.783396</td>\n",
              "      <td>11.353198</td>\n",
              "      <td>41.21739</td>\n",
              "      <td>101.785679</td>\n",
              "      <td>2.709423</td>\n",
              "      <td>371.935971</td>\n",
              "      <td>530.961675</td>\n",
              "      <td>132.403910</td>\n",
              "      <td>153.286836</td>\n",
              "      <td>0.141592</td>\n",
              "      <td>68.312944</td>\n",
              "      <td>25.731393</td>\n",
              "      <td>70.983085</td>\n",
              "      <td>61.099606</td>\n",
              "      <td>94.517683</td>\n",
              "      <td>16.637458</td>\n",
              "      <td>94.760417</td>\n",
              "      <td>93.546109</td>\n",
              "      <td>85.789475</td>\n",
              "      <td>128.712688</td>\n",
              "      <td>49.233935</td>\n",
              "      <td>157.580267</td>\n",
              "      <td>177.240248</td>\n",
              "      <td>62.242703</td>\n",
              "      <td>191.026108</td>\n",
              "      <td>89.022043</td>\n",
              "      <td>143.456867</td>\n",
              "      <td>99.928586</td>\n",
              "      <td>231.821386</td>\n",
              "      <td>0.316786</td>\n",
              "      <td>182.744118</td>\n",
              "      <td>186.155725</td>\n",
              "      <td>124.102784</td>\n",
              "      <td>67.093694</td>\n",
              "      <td>135.987939</td>\n",
              "      <td>202.729060</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>0.240037</td>\n",
              "      <td>0.321103</td>\n",
              "      <td>0.439820</td>\n",
              "      <td>0.475907</td>\n",
              "      <td>0.239543</td>\n",
              "      <td>0.304999</td>\n",
              "      <td>0.186218</td>\n",
              "      <td>0.226492</td>\n",
              "      <td>0.521544</td>\n",
              "      <td>0.552247</td>\n",
              "      <td>0.510389</td>\n",
              "      <td>0.531891</td>\n",
              "      <td>0.022851</td>\n",
              "      <td>0.332787</td>\n",
              "      <td>0.342085</td>\n",
              "      <td>0.364560</td>\n",
              "      <td>0.371654</td>\n",
              "      <td>0.425479</td>\n",
              "      <td>0.458769</td>\n",
              "      <td>0.339752</td>\n",
              "      <td>0.359792</td>\n",
              "      <td>0.248966</td>\n",
              "      <td>0.306040</td>\n",
              "      <td>0.185509</td>\n",
              "      <td>0.207378</td>\n",
              "      <td>0.028901</td>\n",
              "      <td>0.031436</td>\n",
              "      <td>0.510507</td>\n",
              "      <td>0.553574</td>\n",
              "      <td>0.356318</td>\n",
              "      <td>0.367834</td>\n",
              "      <td>0.341203</td>\n",
              "      <td>0.356876</td>\n",
              "      <td>0.516015</td>\n",
              "      <td>0.539235</td>\n",
              "      <td>0.693882</td>\n",
              "      <td>0.862675</td>\n",
              "      <td>0.453426</td>\n",
              "      <td>0.506937</td>\n",
              "      <td>0.027655</td>\n",
              "      <td>0.383964</td>\n",
              "      <td>0.434360</td>\n",
              "      <td>0.647636</td>\n",
              "      <td>0.738306</td>\n",
              "      <td>0.166645</td>\n",
              "      <td>0.231641</td>\n",
              "      <td>0.507784</td>\n",
              "      <td>0.542471</td>\n",
              "      <td>0.374739</td>\n",
              "      <td>0.404220</td>\n",
              "      <td>0.439467</td>\n",
              "      <td>0.511402</td>\n",
              "      <td>0.534515</td>\n",
              "      <td>0.394029</td>\n",
              "      <td>0.674774</td>\n",
              "      <td>0.349482</td>\n",
              "      <td>0.374611</td>\n",
              "      <td>0.380377</td>\n",
              "      <td>...</td>\n",
              "      <td>1304.395428</td>\n",
              "      <td>2251.429647</td>\n",
              "      <td>1596.621628</td>\n",
              "      <td>225.991041</td>\n",
              "      <td>638.130103</td>\n",
              "      <td>318.872244</td>\n",
              "      <td>225.304837</td>\n",
              "      <td>66.283284</td>\n",
              "      <td>75.350497</td>\n",
              "      <td>70.841693</td>\n",
              "      <td>912.198953</td>\n",
              "      <td>1233.851264</td>\n",
              "      <td>1048.212356</td>\n",
              "      <td>634.164242</td>\n",
              "      <td>747.043020</td>\n",
              "      <td>680.276486</td>\n",
              "      <td>20.934257</td>\n",
              "      <td>27.790722</td>\n",
              "      <td>0.513986</td>\n",
              "      <td>0.923735</td>\n",
              "      <td>1.568529</td>\n",
              "      <td>0.338419</td>\n",
              "      <td>3.257427</td>\n",
              "      <td>0.191634</td>\n",
              "      <td>1.076463</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.598261</td>\n",
              "      <td>0.790309</td>\n",
              "      <td>16.579363</td>\n",
              "      <td>3.868017</td>\n",
              "      <td>20.503040</td>\n",
              "      <td>39.608404</td>\n",
              "      <td>25.906506</td>\n",
              "      <td>3.255640</td>\n",
              "      <td>0.626812</td>\n",
              "      <td>3.168491</td>\n",
              "      <td>1.719834</td>\n",
              "      <td>0.289040</td>\n",
              "      <td>0.317049</td>\n",
              "      <td>0.482676</td>\n",
              "      <td>0.624290</td>\n",
              "      <td>0.528128</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>2340.366681</td>\n",
              "      <td>4394.257176</td>\n",
              "      <td>3015.639763</td>\n",
              "      <td>123.164461</td>\n",
              "      <td>355.508258</td>\n",
              "      <td>111.391074</td>\n",
              "      <td>177.550832</td>\n",
              "      <td>96.323808</td>\n",
              "      <td>173.127457</td>\n",
              "      <td>116.922643</td>\n",
              "      <td>2260.182139</td>\n",
              "      <td>3983.003265</td>\n",
              "      <td>2786.397337</td>\n",
              "      <td>333.129270</td>\n",
              "      <td>474.271828</td>\n",
              "      <td>383.439267</td>\n",
              "      <td>55.743839</td>\n",
              "      <td>106.467772</td>\n",
              "      <td>73.374424</td>\n",
              "      <td>0.303183</td>\n",
              "      <td>3.929171</td>\n",
              "      <td>1.358688</td>\n",
              "      <td>1.57068</td>\n",
              "      <td>8.743791</td>\n",
              "      <td>4.711790</td>\n",
              "      <td>6197.946391</td>\n",
              "      <td>11147.950514</td>\n",
              "      <td>7937.940219</td>\n",
              "      <td>265.961322</td>\n",
              "      <td>404.746249</td>\n",
              "      <td>294.103054</td>\n",
              "      <td>700.321813</td>\n",
              "      <td>1114.146312</td>\n",
              "      <td>841.480465</td>\n",
              "      <td>14.352676</td>\n",
              "      <td>159604.598061</td>\n",
              "      <td>0.597383</td>\n",
              "      <td>0.709789</td>\n",
              "      <td>5.254521</td>\n",
              "      <td>16.472918</td>\n",
              "      <td>11.410702</td>\n",
              "      <td>26.080732</td>\n",
              "      <td>0.982185</td>\n",
              "      <td>2.888210</td>\n",
              "      <td>1.131255</td>\n",
              "      <td>11.769504</td>\n",
              "      <td>93.435337</td>\n",
              "      <td>30.392523</td>\n",
              "      <td>1.573547</td>\n",
              "      <td>141.276876</td>\n",
              "      <td>152.056911</td>\n",
              "      <td>200.853603</td>\n",
              "      <td>6.823112</td>\n",
              "      <td>2.346845</td>\n",
              "      <td>97.406803</td>\n",
              "      <td>32.192881</td>\n",
              "      <td>3.739222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.987000e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.640000e+04</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>1001.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-33.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-193.000000</td>\n",
              "      <td>-83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>-13.000000</td>\n",
              "      <td>-28.000000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-46.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>-36.000000</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-660.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.134756e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.028537e+06</td>\n",
              "      <td>43.140000</td>\n",
              "      <td>6019.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>166.00000</td>\n",
              "      <td>204.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>67963.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>-360.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.282400e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.309639e+06</td>\n",
              "      <td>68.911000</td>\n",
              "      <td>9689.000000</td>\n",
              "      <td>361.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.00000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.916664</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>125988.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>-34.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>341.000000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.429918e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.124764e+07</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>14203.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>226.00000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>187.291672</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.835201</td>\n",
              "      <td>21.200001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>36.374399</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>107.949997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.000000</td>\n",
              "      <td>228757.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>-23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-300.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>533.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>366.750000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.577539e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.581113e+07</td>\n",
              "      <td>31937.391000</td>\n",
              "      <td>18396.000000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>10286.000000</td>\n",
              "      <td>11623.000000</td>\n",
              "      <td>4685.000000</td>\n",
              "      <td>5691.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>2253.000000</td>\n",
              "      <td>2255.000000</td>\n",
              "      <td>3331.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>3257.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>3188.000000</td>\n",
              "      <td>2918.000000</td>\n",
              "      <td>1429.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>864.000000</td>\n",
              "      <td>819.000000</td>\n",
              "      <td>873.000000</td>\n",
              "      <td>843.000000</td>\n",
              "      <td>1707.791626</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>876.000000</td>\n",
              "      <td>670.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>847.000000</td>\n",
              "      <td>878.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>153600.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4000.000000</td>\n",
              "      <td>51200.000000</td>\n",
              "      <td>66000.000000</td>\n",
              "      <td>51200.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>975.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1055.000000</td>\n",
              "      <td>323.000000</td>\n",
              "      <td>868.000000</td>\n",
              "      <td>1286.000000</td>\n",
              "      <td>928.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>145765.000000</td>\n",
              "      <td>108800.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>7519.870117</td>\n",
              "      <td>4817.470215</td>\n",
              "      <td>93630.000000</td>\n",
              "      <td>134021.000000</td>\n",
              "      <td>98476.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>1411.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>15.00000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>55125.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>104060.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>999595.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>229.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>671.000000</td>\n",
              "      <td>661.000000</td>\n",
              "      <td>854.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>548.000000</td>\n",
              "      <td>216.000000</td>\n",
              "      <td>32.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 403 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd7ac8e6-c8be-4328-aefa-cb9aa31febe4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd7ac8e6-c8be-4328-aefa-cb9aa31febe4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd7ac8e6-c8be-4328-aefa-cb9aa31febe4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0c757ac1-0dee-48e2-a7d3-30e17e95ca17\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c757ac1-0dee-48e2-a7d3-30e17e95ca17')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0c757ac1-0dee-48e2-a7d3-30e17e95ca17 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns.to_list()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z6oTNeNeb95y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2448527f-9512-4853-bc82-0bcaf0717d4a"
      },
      "id": "z6oTNeNeb95y",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TransactionID',\n",
              " 'isFraud',\n",
              " 'TransactionDT',\n",
              " 'TransactionAmt',\n",
              " 'ProductCD',\n",
              " 'card1',\n",
              " 'card2',\n",
              " 'card3',\n",
              " 'card4',\n",
              " 'card5',\n",
              " 'card6',\n",
              " 'addr1',\n",
              " 'addr2',\n",
              " 'dist1',\n",
              " 'dist2',\n",
              " 'P_emaildomain',\n",
              " 'R_emaildomain',\n",
              " 'C1',\n",
              " 'C2',\n",
              " 'C3',\n",
              " 'C4',\n",
              " 'C5',\n",
              " 'C6',\n",
              " 'C7',\n",
              " 'C8',\n",
              " 'C9',\n",
              " 'C10',\n",
              " 'C11',\n",
              " 'C12',\n",
              " 'C13',\n",
              " 'C14',\n",
              " 'D1',\n",
              " 'D2',\n",
              " 'D3',\n",
              " 'D4',\n",
              " 'D5',\n",
              " 'D6',\n",
              " 'D7',\n",
              " 'D8',\n",
              " 'D9',\n",
              " 'D10',\n",
              " 'D11',\n",
              " 'D12',\n",
              " 'D13',\n",
              " 'D14',\n",
              " 'D15',\n",
              " 'M1',\n",
              " 'M2',\n",
              " 'M3',\n",
              " 'M4',\n",
              " 'M5',\n",
              " 'M6',\n",
              " 'M7',\n",
              " 'M8',\n",
              " 'M9',\n",
              " 'V1',\n",
              " 'V2',\n",
              " 'V3',\n",
              " 'V4',\n",
              " 'V5',\n",
              " 'V6',\n",
              " 'V7',\n",
              " 'V8',\n",
              " 'V9',\n",
              " 'V10',\n",
              " 'V11',\n",
              " 'V12',\n",
              " 'V13',\n",
              " 'V14',\n",
              " 'V15',\n",
              " 'V16',\n",
              " 'V17',\n",
              " 'V18',\n",
              " 'V19',\n",
              " 'V20',\n",
              " 'V21',\n",
              " 'V22',\n",
              " 'V23',\n",
              " 'V24',\n",
              " 'V25',\n",
              " 'V26',\n",
              " 'V27',\n",
              " 'V28',\n",
              " 'V29',\n",
              " 'V30',\n",
              " 'V31',\n",
              " 'V32',\n",
              " 'V33',\n",
              " 'V34',\n",
              " 'V35',\n",
              " 'V36',\n",
              " 'V37',\n",
              " 'V38',\n",
              " 'V39',\n",
              " 'V40',\n",
              " 'V41',\n",
              " 'V42',\n",
              " 'V43',\n",
              " 'V44',\n",
              " 'V45',\n",
              " 'V46',\n",
              " 'V47',\n",
              " 'V48',\n",
              " 'V49',\n",
              " 'V50',\n",
              " 'V51',\n",
              " 'V52',\n",
              " 'V53',\n",
              " 'V54',\n",
              " 'V55',\n",
              " 'V56',\n",
              " 'V57',\n",
              " 'V58',\n",
              " 'V59',\n",
              " 'V60',\n",
              " 'V61',\n",
              " 'V62',\n",
              " 'V63',\n",
              " 'V64',\n",
              " 'V65',\n",
              " 'V66',\n",
              " 'V67',\n",
              " 'V68',\n",
              " 'V69',\n",
              " 'V70',\n",
              " 'V71',\n",
              " 'V72',\n",
              " 'V73',\n",
              " 'V74',\n",
              " 'V75',\n",
              " 'V76',\n",
              " 'V77',\n",
              " 'V78',\n",
              " 'V79',\n",
              " 'V80',\n",
              " 'V81',\n",
              " 'V82',\n",
              " 'V83',\n",
              " 'V84',\n",
              " 'V85',\n",
              " 'V86',\n",
              " 'V87',\n",
              " 'V88',\n",
              " 'V89',\n",
              " 'V90',\n",
              " 'V91',\n",
              " 'V92',\n",
              " 'V93',\n",
              " 'V94',\n",
              " 'V95',\n",
              " 'V96',\n",
              " 'V97',\n",
              " 'V98',\n",
              " 'V99',\n",
              " 'V100',\n",
              " 'V101',\n",
              " 'V102',\n",
              " 'V103',\n",
              " 'V104',\n",
              " 'V105',\n",
              " 'V106',\n",
              " 'V107',\n",
              " 'V108',\n",
              " 'V109',\n",
              " 'V110',\n",
              " 'V111',\n",
              " 'V112',\n",
              " 'V113',\n",
              " 'V114',\n",
              " 'V115',\n",
              " 'V116',\n",
              " 'V117',\n",
              " 'V118',\n",
              " 'V119',\n",
              " 'V120',\n",
              " 'V121',\n",
              " 'V122',\n",
              " 'V123',\n",
              " 'V124',\n",
              " 'V125',\n",
              " 'V126',\n",
              " 'V127',\n",
              " 'V128',\n",
              " 'V129',\n",
              " 'V130',\n",
              " 'V131',\n",
              " 'V132',\n",
              " 'V133',\n",
              " 'V134',\n",
              " 'V135',\n",
              " 'V136',\n",
              " 'V137',\n",
              " 'V138',\n",
              " 'V139',\n",
              " 'V140',\n",
              " 'V141',\n",
              " 'V142',\n",
              " 'V143',\n",
              " 'V144',\n",
              " 'V145',\n",
              " 'V146',\n",
              " 'V147',\n",
              " 'V148',\n",
              " 'V149',\n",
              " 'V150',\n",
              " 'V151',\n",
              " 'V152',\n",
              " 'V153',\n",
              " 'V154',\n",
              " 'V155',\n",
              " 'V156',\n",
              " 'V157',\n",
              " 'V158',\n",
              " 'V159',\n",
              " 'V160',\n",
              " 'V161',\n",
              " 'V162',\n",
              " 'V163',\n",
              " 'V164',\n",
              " 'V165',\n",
              " 'V166',\n",
              " 'V167',\n",
              " 'V168',\n",
              " 'V169',\n",
              " 'V170',\n",
              " 'V171',\n",
              " 'V172',\n",
              " 'V173',\n",
              " 'V174',\n",
              " 'V175',\n",
              " 'V176',\n",
              " 'V177',\n",
              " 'V178',\n",
              " 'V179',\n",
              " 'V180',\n",
              " 'V181',\n",
              " 'V182',\n",
              " 'V183',\n",
              " 'V184',\n",
              " 'V185',\n",
              " 'V186',\n",
              " 'V187',\n",
              " 'V188',\n",
              " 'V189',\n",
              " 'V190',\n",
              " 'V191',\n",
              " 'V192',\n",
              " 'V193',\n",
              " 'V194',\n",
              " 'V195',\n",
              " 'V196',\n",
              " 'V197',\n",
              " 'V198',\n",
              " 'V199',\n",
              " 'V200',\n",
              " 'V201',\n",
              " 'V202',\n",
              " 'V203',\n",
              " 'V204',\n",
              " 'V205',\n",
              " 'V206',\n",
              " 'V207',\n",
              " 'V208',\n",
              " 'V209',\n",
              " 'V210',\n",
              " 'V211',\n",
              " 'V212',\n",
              " 'V213',\n",
              " 'V214',\n",
              " 'V215',\n",
              " 'V216',\n",
              " 'V217',\n",
              " 'V218',\n",
              " 'V219',\n",
              " 'V220',\n",
              " 'V221',\n",
              " 'V222',\n",
              " 'V223',\n",
              " 'V224',\n",
              " 'V225',\n",
              " 'V226',\n",
              " 'V227',\n",
              " 'V228',\n",
              " 'V229',\n",
              " 'V230',\n",
              " 'V231',\n",
              " 'V232',\n",
              " 'V233',\n",
              " 'V234',\n",
              " 'V235',\n",
              " 'V236',\n",
              " 'V237',\n",
              " 'V238',\n",
              " 'V239',\n",
              " 'V240',\n",
              " 'V241',\n",
              " 'V242',\n",
              " 'V243',\n",
              " 'V244',\n",
              " 'V245',\n",
              " 'V246',\n",
              " 'V247',\n",
              " 'V248',\n",
              " 'V249',\n",
              " 'V250',\n",
              " 'V251',\n",
              " 'V252',\n",
              " 'V253',\n",
              " 'V254',\n",
              " 'V255',\n",
              " 'V256',\n",
              " 'V257',\n",
              " 'V258',\n",
              " 'V259',\n",
              " 'V260',\n",
              " 'V261',\n",
              " 'V262',\n",
              " 'V263',\n",
              " 'V264',\n",
              " 'V265',\n",
              " 'V266',\n",
              " 'V267',\n",
              " 'V268',\n",
              " 'V269',\n",
              " 'V270',\n",
              " 'V271',\n",
              " 'V272',\n",
              " 'V273',\n",
              " 'V274',\n",
              " 'V275',\n",
              " 'V276',\n",
              " 'V277',\n",
              " 'V278',\n",
              " 'V279',\n",
              " 'V280',\n",
              " 'V281',\n",
              " 'V282',\n",
              " 'V283',\n",
              " 'V284',\n",
              " 'V285',\n",
              " 'V286',\n",
              " 'V287',\n",
              " 'V288',\n",
              " 'V289',\n",
              " 'V290',\n",
              " 'V291',\n",
              " 'V292',\n",
              " 'V293',\n",
              " 'V294',\n",
              " 'V295',\n",
              " 'V296',\n",
              " 'V297',\n",
              " 'V298',\n",
              " 'V299',\n",
              " 'V300',\n",
              " 'V301',\n",
              " 'V302',\n",
              " 'V303',\n",
              " 'V304',\n",
              " 'V305',\n",
              " 'V306',\n",
              " 'V307',\n",
              " 'V308',\n",
              " 'V309',\n",
              " 'V310',\n",
              " 'V311',\n",
              " 'V312',\n",
              " 'V313',\n",
              " 'V314',\n",
              " 'V315',\n",
              " 'V316',\n",
              " 'V317',\n",
              " 'V318',\n",
              " 'V319',\n",
              " 'V320',\n",
              " 'V321',\n",
              " 'V322',\n",
              " 'V323',\n",
              " 'V324',\n",
              " 'V325',\n",
              " 'V326',\n",
              " 'V327',\n",
              " 'V328',\n",
              " 'V329',\n",
              " 'V330',\n",
              " 'V331',\n",
              " 'V332',\n",
              " 'V333',\n",
              " 'V334',\n",
              " 'V335',\n",
              " 'V336',\n",
              " 'V337',\n",
              " 'V338',\n",
              " 'V339',\n",
              " 'id_01',\n",
              " 'id_02',\n",
              " 'id_03',\n",
              " 'id_04',\n",
              " 'id_05',\n",
              " 'id_06',\n",
              " 'id_07',\n",
              " 'id_08',\n",
              " 'id_09',\n",
              " 'id_10',\n",
              " 'id_11',\n",
              " 'id_12',\n",
              " 'id_13',\n",
              " 'id_14',\n",
              " 'id_15',\n",
              " 'id_16',\n",
              " 'id_17',\n",
              " 'id_18',\n",
              " 'id_19',\n",
              " 'id_20',\n",
              " 'id_21',\n",
              " 'id_22',\n",
              " 'id_23',\n",
              " 'id_24',\n",
              " 'id_25',\n",
              " 'id_26',\n",
              " 'id_27',\n",
              " 'id_28',\n",
              " 'id_29',\n",
              " 'id_30',\n",
              " 'id_31',\n",
              " 'id_32',\n",
              " 'id_33',\n",
              " 'id_34',\n",
              " 'id_35',\n",
              " 'id_36',\n",
              " 'id_37',\n",
              " 'id_38',\n",
              " 'DeviceType',\n",
              " 'DeviceInfo']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data.isna().sum()/train_data.shape[0]).sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "kw_UTytum-ho",
        "outputId": "b8499cef-353f-49df-d050-1440493b9932"
      },
      "id": "kw_UTytum-ho",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id_24             0.991971\n",
              "id_25             0.991317\n",
              "id_07             0.991292\n",
              "id_08             0.991292\n",
              "id_21             0.991281\n",
              "                    ...   \n",
              "ProductCD         0.000000\n",
              "TransactionAmt    0.000000\n",
              "TransactionDT     0.000000\n",
              "isFraud           0.000000\n",
              "TransactionID     0.000000\n",
              "Length: 434, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>0.991971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>0.991317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>0.991292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>0.991281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ProductCD</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionDT</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionID</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>434 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['id_24'].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_4NwgfQtj6k",
        "outputId": "8aa234c6-6f49-4688-b29a-edd6aca235d5"
      },
      "id": "o_4NwgfQtj6k",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(468639)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data[:50000]"
      ],
      "metadata": {
        "id": "sN2wZF2pc8hg"
      },
      "id": "sN2wZF2pc8hg",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEWFXwd-de1O",
        "outputId": "3327f0f5-949a-462b-be9b-b1c59cf16aa7"
      },
      "id": "eEWFXwd-de1O",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 434)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import time\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='medium_quality',tuning_data=val_data, time_limit=600, num_gpus=1\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWRUVCjpax8u",
        "outputId": "4280347a-08e5-4cb0-888e-ee977cb67c28"
      },
      "id": "FWRUVCjpax8u",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          8\n",
            "GPU Count:          1\n",
            "Memory Avail:       43.63 GB / 50.99 GB (85.6%)\n",
            "Disk Space Avail:   179.49 GB / 235.68 GB (76.2%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': False}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels\"\n",
            "Train Data Rows:    50000\n",
            "Train Data Columns: 433\n",
            "Tuning Data Rows:    59054\n",
            "Tuning Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    44378.13 MB\n",
            "\tTrain Data (Original)  Memory Usage: 463.42 MB (1.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.1s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t0.3s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t8 duplicate columns removed: ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.8s = Fit runtime\n",
            "\t\t\t425 features in original data used to generate 425 features in processed data.\n",
            "\tUnused Original Features (Count: 8): ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 8 | ['V113', 'V119', 'V147', 'V149', 'V154', ...]\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t8.0s = Fit runtime\n",
            "\t425 features in original data used to generate 425 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 331.16 MB (0.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 8.87s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/data/y.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/data/X_val.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/data/y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 591.13s of the 591.12s of remaining time.\n",
            "\tFitting LightGBMXT with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.9/43.1 GB\n",
            "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.100628\n",
            "[100]\tvalid_set's binary_logloss: 0.094533\n",
            "[150]\tvalid_set's binary_logloss: 0.0912681\n",
            "[200]\tvalid_set's binary_logloss: 0.089794\n",
            "[250]\tvalid_set's binary_logloss: 0.0888166\n",
            "[300]\tvalid_set's binary_logloss: 0.0882118\n",
            "[350]\tvalid_set's binary_logloss: 0.087822\n",
            "[400]\tvalid_set's binary_logloss: 0.0875146\n",
            "[450]\tvalid_set's binary_logloss: 0.0874778\n",
            "[500]\tvalid_set's binary_logloss: 0.0873865\n",
            "[550]\tvalid_set's binary_logloss: 0.087331\n",
            "[600]\tvalid_set's binary_logloss: 0.0874516\n",
            "[650]\tvalid_set's binary_logloss: 0.087537\n",
            "[700]\tvalid_set's binary_logloss: 0.0877828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "\t0.9015\t = Validation score   (roc_auc)\n",
            "\t19.4s\t = Training   runtime\n",
            "\t1.79s\t = Validation runtime\n",
            "\t32958.1\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM ... Training model for up to 569.88s of the 569.87s of remaining time.\n",
            "\tFitting LightGBM with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.9/43.0 GB\n",
            "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0966024\n",
            "[100]\tvalid_set's binary_logloss: 0.0912058\n",
            "[150]\tvalid_set's binary_logloss: 0.0888264\n",
            "[200]\tvalid_set's binary_logloss: 0.0877186\n",
            "[250]\tvalid_set's binary_logloss: 0.0867219\n",
            "[300]\tvalid_set's binary_logloss: 0.0864514\n",
            "[350]\tvalid_set's binary_logloss: 0.0862687\n",
            "[400]\tvalid_set's binary_logloss: 0.0863432\n",
            "[450]\tvalid_set's binary_logloss: 0.086572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "\t0.9069\t = Validation score   (roc_auc)\n",
            "\t8.42s\t = Training   runtime\n",
            "\t0.9s\t = Validation runtime\n",
            "\t65738.8\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini ... Training model for up to 560.51s of the 560.50s of remaining time.\n",
            "\tFitting RandomForestGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/43.0 GB\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "\t0.8802\t = Validation score   (roc_auc)\n",
            "\t15.38s\t = Training   runtime\n",
            "\t1.39s\t = Validation runtime\n",
            "\t42479.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr ... Training model for up to 543.50s of the 543.49s of remaining time.\n",
            "\tFitting RandomForestEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.9 GB\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "\t0.8833\t = Validation score   (roc_auc)\n",
            "\t11.58s\t = Training   runtime\n",
            "\t1.16s\t = Validation runtime\n",
            "\t50758.6\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost ... Training model for up to 530.48s of the 530.47s of remaining time.\n",
            "\tFitting CatBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.6/42.9 GB\n",
            "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 4, 'task_type': 'GPU'}\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6106130\ttest: 0.6110668\tbest: 0.6110668 (0)\ttotal: 26.8ms\tremaining: 241ms\n",
            "9:\tlearn: 0.2458242\ttest: 0.2465552\tbest: 0.2465552 (9)\ttotal: 202ms\tremaining: 0us\n",
            "bestTest = 0.2465552086\n",
            "bestIteration = 9\n",
            "0:\tlearn: 0.6082404\ttest: 0.6080877\tbest: 0.6080877 (0)\ttotal: 41.3ms\tremaining: 2m 49s\n",
            "20:\tlearn: 0.1458957\ttest: 0.1472668\tbest: 0.1472668 (20)\ttotal: 735ms\tremaining: 2m 22s\n",
            "40:\tlearn: 0.1115550\ttest: 0.1145953\tbest: 0.1145953 (40)\ttotal: 1.44s\tremaining: 2m 22s\n",
            "60:\tlearn: 0.1033405\ttest: 0.1078201\tbest: 0.1078201 (60)\ttotal: 2.15s\tremaining: 2m 22s\n",
            "80:\tlearn: 0.0990221\ttest: 0.1044875\tbest: 0.1044875 (80)\ttotal: 2.86s\tremaining: 2m 21s\n",
            "100:\tlearn: 0.0970006\ttest: 0.1031563\tbest: 0.1031563 (100)\ttotal: 3.57s\tremaining: 2m 21s\n",
            "120:\tlearn: 0.0953476\ttest: 0.1020479\tbest: 0.1020479 (120)\ttotal: 4.28s\tremaining: 2m 20s\n",
            "140:\tlearn: 0.0936412\ttest: 0.1008461\tbest: 0.1008461 (140)\ttotal: 4.99s\tremaining: 2m 20s\n",
            "160:\tlearn: 0.0923088\ttest: 0.1000622\tbest: 0.1000622 (160)\ttotal: 5.68s\tremaining: 2m 19s\n",
            "180:\tlearn: 0.0913430\ttest: 0.0994953\tbest: 0.0994953 (180)\ttotal: 6.43s\tremaining: 2m 19s\n",
            "200:\tlearn: 0.0902623\ttest: 0.0988596\tbest: 0.0988596 (200)\ttotal: 7.2s\tremaining: 2m 19s\n",
            "220:\tlearn: 0.0891800\ttest: 0.0983091\tbest: 0.0983091 (220)\ttotal: 7.95s\tremaining: 2m 19s\n",
            "240:\tlearn: 0.0884166\ttest: 0.0979484\tbest: 0.0979484 (240)\ttotal: 8.68s\tremaining: 2m 19s\n",
            "260:\tlearn: 0.0876671\ttest: 0.0975794\tbest: 0.0975794 (260)\ttotal: 9.41s\tremaining: 2m 18s\n",
            "280:\tlearn: 0.0868882\ttest: 0.0972811\tbest: 0.0972811 (280)\ttotal: 10.1s\tremaining: 2m 17s\n",
            "300:\tlearn: 0.0861909\ttest: 0.0969416\tbest: 0.0969416 (300)\ttotal: 10.9s\tremaining: 2m 17s\n",
            "320:\tlearn: 0.0854554\ttest: 0.0966069\tbest: 0.0966069 (320)\ttotal: 11.6s\tremaining: 2m 16s\n",
            "340:\tlearn: 0.0846833\ttest: 0.0962509\tbest: 0.0962509 (340)\ttotal: 12.3s\tremaining: 2m 16s\n",
            "360:\tlearn: 0.0838325\ttest: 0.0958463\tbest: 0.0958463 (360)\ttotal: 13.1s\tremaining: 2m 15s\n",
            "380:\tlearn: 0.0832743\ttest: 0.0956359\tbest: 0.0956359 (380)\ttotal: 13.8s\tremaining: 2m 14s\n",
            "400:\tlearn: 0.0825602\ttest: 0.0953915\tbest: 0.0953915 (400)\ttotal: 14.5s\tremaining: 2m 13s\n",
            "420:\tlearn: 0.0819680\ttest: 0.0952066\tbest: 0.0952066 (420)\ttotal: 15.2s\tremaining: 2m 12s\n",
            "440:\tlearn: 0.0813191\ttest: 0.0949790\tbest: 0.0949790 (440)\ttotal: 16s\tremaining: 2m 12s\n",
            "460:\tlearn: 0.0806700\ttest: 0.0947315\tbest: 0.0947315 (460)\ttotal: 16.7s\tremaining: 2m 11s\n",
            "480:\tlearn: 0.0800504\ttest: 0.0944852\tbest: 0.0944852 (480)\ttotal: 17.4s\tremaining: 2m 10s\n",
            "500:\tlearn: 0.0794311\ttest: 0.0942722\tbest: 0.0942722 (500)\ttotal: 18.1s\tremaining: 2m 10s\n",
            "520:\tlearn: 0.0789084\ttest: 0.0940749\tbest: 0.0940749 (520)\ttotal: 18.8s\tremaining: 2m 9s\n",
            "540:\tlearn: 0.0783830\ttest: 0.0938718\tbest: 0.0938718 (540)\ttotal: 19.5s\tremaining: 2m 8s\n",
            "560:\tlearn: 0.0778949\ttest: 0.0937134\tbest: 0.0937134 (560)\ttotal: 20.3s\tremaining: 2m 7s\n",
            "580:\tlearn: 0.0774402\ttest: 0.0936064\tbest: 0.0935913 (579)\ttotal: 21s\tremaining: 2m 7s\n",
            "600:\tlearn: 0.0769437\ttest: 0.0933959\tbest: 0.0933959 (600)\ttotal: 21.8s\tremaining: 2m 6s\n",
            "620:\tlearn: 0.0764861\ttest: 0.0932490\tbest: 0.0932490 (620)\ttotal: 22.5s\tremaining: 2m 6s\n",
            "640:\tlearn: 0.0760139\ttest: 0.0930760\tbest: 0.0930752 (637)\ttotal: 23.2s\tremaining: 2m 5s\n",
            "660:\tlearn: 0.0755055\ttest: 0.0929188\tbest: 0.0929188 (660)\ttotal: 23.9s\tremaining: 2m 4s\n",
            "680:\tlearn: 0.0750519\ttest: 0.0927690\tbest: 0.0927690 (680)\ttotal: 24.7s\tremaining: 2m 3s\n",
            "700:\tlearn: 0.0746161\ttest: 0.0925707\tbest: 0.0925707 (700)\ttotal: 25.4s\tremaining: 2m 3s\n",
            "720:\tlearn: 0.0741858\ttest: 0.0924375\tbest: 0.0924375 (720)\ttotal: 26.1s\tremaining: 2m 2s\n",
            "740:\tlearn: 0.0737981\ttest: 0.0923826\tbest: 0.0923807 (739)\ttotal: 26.8s\tremaining: 2m 1s\n",
            "760:\tlearn: 0.0733387\ttest: 0.0922768\tbest: 0.0922768 (760)\ttotal: 27.5s\tremaining: 2m\n",
            "780:\tlearn: 0.0729212\ttest: 0.0921639\tbest: 0.0921639 (780)\ttotal: 28.3s\tremaining: 2m\n",
            "800:\tlearn: 0.0725432\ttest: 0.0920887\tbest: 0.0920850 (799)\ttotal: 29s\tremaining: 1m 59s\n",
            "820:\tlearn: 0.0720405\ttest: 0.0919940\tbest: 0.0919940 (820)\ttotal: 29.7s\tremaining: 1m 58s\n",
            "840:\tlearn: 0.0716789\ttest: 0.0919015\tbest: 0.0919015 (840)\ttotal: 30.5s\tremaining: 1m 58s\n",
            "860:\tlearn: 0.0712315\ttest: 0.0917151\tbest: 0.0917151 (860)\ttotal: 31.2s\tremaining: 1m 57s\n",
            "880:\tlearn: 0.0708381\ttest: 0.0915869\tbest: 0.0915869 (880)\ttotal: 32s\tremaining: 1m 56s\n",
            "900:\tlearn: 0.0704576\ttest: 0.0915074\tbest: 0.0915074 (900)\ttotal: 32.7s\tremaining: 1m 56s\n",
            "920:\tlearn: 0.0701648\ttest: 0.0914528\tbest: 0.0914528 (920)\ttotal: 33.4s\tremaining: 1m 55s\n",
            "940:\tlearn: 0.0697173\ttest: 0.0913685\tbest: 0.0913685 (940)\ttotal: 34.2s\tremaining: 1m 54s\n",
            "960:\tlearn: 0.0692875\ttest: 0.0912736\tbest: 0.0912722 (957)\ttotal: 35s\tremaining: 1m 54s\n",
            "980:\tlearn: 0.0688306\ttest: 0.0911574\tbest: 0.0911574 (980)\ttotal: 35.7s\tremaining: 1m 53s\n",
            "1000:\tlearn: 0.0683851\ttest: 0.0910446\tbest: 0.0910446 (1000)\ttotal: 36.5s\tremaining: 1m 52s\n",
            "1020:\tlearn: 0.0680024\ttest: 0.0909292\tbest: 0.0909292 (1020)\ttotal: 37.2s\tremaining: 1m 52s\n",
            "1040:\tlearn: 0.0675866\ttest: 0.0908493\tbest: 0.0908483 (1039)\ttotal: 37.9s\tremaining: 1m 51s\n",
            "1060:\tlearn: 0.0672017\ttest: 0.0907746\tbest: 0.0907743 (1059)\ttotal: 38.6s\tremaining: 1m 50s\n",
            "1080:\tlearn: 0.0668279\ttest: 0.0907024\tbest: 0.0907013 (1079)\ttotal: 39.4s\tremaining: 1m 49s\n",
            "1100:\tlearn: 0.0665148\ttest: 0.0906224\tbest: 0.0906224 (1100)\ttotal: 40.1s\tremaining: 1m 49s\n",
            "1120:\tlearn: 0.0662012\ttest: 0.0905525\tbest: 0.0905525 (1120)\ttotal: 40.8s\tremaining: 1m 48s\n",
            "1140:\tlearn: 0.0659006\ttest: 0.0905294\tbest: 0.0905236 (1138)\ttotal: 41.5s\tremaining: 1m 47s\n",
            "1160:\tlearn: 0.0655426\ttest: 0.0904437\tbest: 0.0904437 (1160)\ttotal: 42.3s\tremaining: 1m 47s\n",
            "1180:\tlearn: 0.0651962\ttest: 0.0903700\tbest: 0.0903697 (1179)\ttotal: 43s\tremaining: 1m 46s\n",
            "1200:\tlearn: 0.0648612\ttest: 0.0902836\tbest: 0.0902836 (1200)\ttotal: 43.8s\tremaining: 1m 45s\n",
            "1220:\tlearn: 0.0645587\ttest: 0.0902044\tbest: 0.0902044 (1220)\ttotal: 44.5s\tremaining: 1m 44s\n",
            "1240:\tlearn: 0.0642570\ttest: 0.0901360\tbest: 0.0901360 (1240)\ttotal: 45.2s\tremaining: 1m 44s\n",
            "1260:\tlearn: 0.0638438\ttest: 0.0900742\tbest: 0.0900680 (1257)\ttotal: 46s\tremaining: 1m 43s\n",
            "1280:\tlearn: 0.0635100\ttest: 0.0900427\tbest: 0.0900423 (1279)\ttotal: 46.7s\tremaining: 1m 42s\n",
            "1300:\tlearn: 0.0631336\ttest: 0.0899944\tbest: 0.0899944 (1300)\ttotal: 47.5s\tremaining: 1m 42s\n",
            "1320:\tlearn: 0.0626995\ttest: 0.0898859\tbest: 0.0898831 (1318)\ttotal: 48.2s\tremaining: 1m 41s\n",
            "1340:\tlearn: 0.0623652\ttest: 0.0898369\tbest: 0.0898369 (1340)\ttotal: 48.9s\tremaining: 1m 40s\n",
            "1360:\tlearn: 0.0620195\ttest: 0.0897360\tbest: 0.0897360 (1360)\ttotal: 49.6s\tremaining: 1m 39s\n",
            "1380:\tlearn: 0.0617398\ttest: 0.0897291\tbest: 0.0897287 (1362)\ttotal: 50.4s\tremaining: 1m 39s\n",
            "1400:\tlearn: 0.0614535\ttest: 0.0897157\tbest: 0.0897127 (1398)\ttotal: 51.1s\tremaining: 1m 38s\n",
            "1420:\tlearn: 0.0611284\ttest: 0.0896726\tbest: 0.0896601 (1417)\ttotal: 51.8s\tremaining: 1m 37s\n",
            "1440:\tlearn: 0.0608726\ttest: 0.0896083\tbest: 0.0896037 (1438)\ttotal: 52.5s\tremaining: 1m 36s\n",
            "1460:\tlearn: 0.0606044\ttest: 0.0895986\tbest: 0.0895951 (1459)\ttotal: 53.3s\tremaining: 1m 36s\n",
            "1480:\tlearn: 0.0603307\ttest: 0.0895425\tbest: 0.0895416 (1479)\ttotal: 54.1s\tremaining: 1m 35s\n",
            "1500:\tlearn: 0.0599767\ttest: 0.0894772\tbest: 0.0894772 (1500)\ttotal: 54.8s\tremaining: 1m 34s\n",
            "1520:\tlearn: 0.0597090\ttest: 0.0894115\tbest: 0.0894115 (1520)\ttotal: 55.6s\tremaining: 1m 34s\n",
            "1540:\tlearn: 0.0594033\ttest: 0.0894024\tbest: 0.0894024 (1540)\ttotal: 56.4s\tremaining: 1m 33s\n",
            "1560:\tlearn: 0.0590890\ttest: 0.0893274\tbest: 0.0893265 (1559)\ttotal: 57.1s\tremaining: 1m 32s\n",
            "1580:\tlearn: 0.0588393\ttest: 0.0892856\tbest: 0.0892856 (1580)\ttotal: 57.9s\tremaining: 1m 32s\n",
            "1600:\tlearn: 0.0585315\ttest: 0.0892112\tbest: 0.0892055 (1597)\ttotal: 58.6s\tremaining: 1m 31s\n",
            "1620:\tlearn: 0.0582289\ttest: 0.0892193\tbest: 0.0892055 (1597)\ttotal: 59.4s\tremaining: 1m 30s\n",
            "1640:\tlearn: 0.0578967\ttest: 0.0891686\tbest: 0.0891681 (1639)\ttotal: 1m\tremaining: 1m 30s\n",
            "1660:\tlearn: 0.0576240\ttest: 0.0891214\tbest: 0.0891214 (1660)\ttotal: 1m\tremaining: 1m 29s\n",
            "1680:\tlearn: 0.0573802\ttest: 0.0890915\tbest: 0.0890915 (1680)\ttotal: 1m 1s\tremaining: 1m 28s\n",
            "1700:\tlearn: 0.0570811\ttest: 0.0890649\tbest: 0.0890649 (1700)\ttotal: 1m 2s\tremaining: 1m 28s\n",
            "1720:\tlearn: 0.0567670\ttest: 0.0890588\tbest: 0.0890588 (1720)\ttotal: 1m 3s\tremaining: 1m 27s\n",
            "1740:\tlearn: 0.0565251\ttest: 0.0889639\tbest: 0.0889630 (1739)\ttotal: 1m 4s\tremaining: 1m 26s\n",
            "1760:\tlearn: 0.0562485\ttest: 0.0889437\tbest: 0.0889437 (1760)\ttotal: 1m 4s\tremaining: 1m 25s\n",
            "1780:\tlearn: 0.0559710\ttest: 0.0889269\tbest: 0.0889234 (1779)\ttotal: 1m 5s\tremaining: 1m 25s\n",
            "1800:\tlearn: 0.0557590\ttest: 0.0889013\tbest: 0.0888955 (1796)\ttotal: 1m 6s\tremaining: 1m 24s\n",
            "1820:\tlearn: 0.0554230\ttest: 0.0888844\tbest: 0.0888801 (1808)\ttotal: 1m 6s\tremaining: 1m 23s\n",
            "1840:\tlearn: 0.0551580\ttest: 0.0888852\tbest: 0.0888624 (1835)\ttotal: 1m 7s\tremaining: 1m 23s\n",
            "1860:\tlearn: 0.0549317\ttest: 0.0888491\tbest: 0.0888487 (1858)\ttotal: 1m 8s\tremaining: 1m 22s\n",
            "1880:\tlearn: 0.0546938\ttest: 0.0888116\tbest: 0.0888079 (1878)\ttotal: 1m 9s\tremaining: 1m 21s\n",
            "1900:\tlearn: 0.0544679\ttest: 0.0887995\tbest: 0.0887931 (1884)\ttotal: 1m 9s\tremaining: 1m 20s\n",
            "1920:\tlearn: 0.0541697\ttest: 0.0887929\tbest: 0.0887792 (1901)\ttotal: 1m 10s\tremaining: 1m 20s\n",
            "1940:\tlearn: 0.0538672\ttest: 0.0887503\tbest: 0.0887500 (1939)\ttotal: 1m 11s\tremaining: 1m 19s\n",
            "1960:\tlearn: 0.0535988\ttest: 0.0886777\tbest: 0.0886717 (1959)\ttotal: 1m 12s\tremaining: 1m 18s\n",
            "1980:\tlearn: 0.0533736\ttest: 0.0886595\tbest: 0.0886577 (1971)\ttotal: 1m 12s\tremaining: 1m 17s\n",
            "2000:\tlearn: 0.0530958\ttest: 0.0886578\tbest: 0.0886509 (1996)\ttotal: 1m 13s\tremaining: 1m 17s\n",
            "2020:\tlearn: 0.0528600\ttest: 0.0886180\tbest: 0.0886114 (2008)\ttotal: 1m 14s\tremaining: 1m 16s\n",
            "2040:\tlearn: 0.0526271\ttest: 0.0886029\tbest: 0.0885929 (2036)\ttotal: 1m 15s\tremaining: 1m 15s\n",
            "2060:\tlearn: 0.0524267\ttest: 0.0885766\tbest: 0.0885766 (2060)\ttotal: 1m 15s\tremaining: 1m 15s\n",
            "2080:\tlearn: 0.0521642\ttest: 0.0885257\tbest: 0.0885257 (2080)\ttotal: 1m 16s\tremaining: 1m 14s\n",
            "2100:\tlearn: 0.0519205\ttest: 0.0885050\tbest: 0.0885011 (2097)\ttotal: 1m 17s\tremaining: 1m 13s\n",
            "2120:\tlearn: 0.0516229\ttest: 0.0884672\tbest: 0.0884672 (2120)\ttotal: 1m 18s\tremaining: 1m 12s\n",
            "2140:\tlearn: 0.0514039\ttest: 0.0884558\tbest: 0.0884544 (2139)\ttotal: 1m 18s\tremaining: 1m 12s\n",
            "2160:\tlearn: 0.0511502\ttest: 0.0884025\tbest: 0.0884025 (2160)\ttotal: 1m 19s\tremaining: 1m 11s\n",
            "2180:\tlearn: 0.0508711\ttest: 0.0883496\tbest: 0.0883496 (2180)\ttotal: 1m 20s\tremaining: 1m 10s\n",
            "2200:\tlearn: 0.0506101\ttest: 0.0882758\tbest: 0.0882758 (2200)\ttotal: 1m 21s\tremaining: 1m 9s\n",
            "2220:\tlearn: 0.0503497\ttest: 0.0882505\tbest: 0.0882399 (2216)\ttotal: 1m 21s\tremaining: 1m 9s\n",
            "2240:\tlearn: 0.0501010\ttest: 0.0882293\tbest: 0.0882211 (2235)\ttotal: 1m 22s\tremaining: 1m 8s\n",
            "2260:\tlearn: 0.0498046\ttest: 0.0882029\tbest: 0.0882007 (2258)\ttotal: 1m 23s\tremaining: 1m 7s\n",
            "2280:\tlearn: 0.0496126\ttest: 0.0881703\tbest: 0.0881650 (2275)\ttotal: 1m 24s\tremaining: 1m 7s\n",
            "2300:\tlearn: 0.0494023\ttest: 0.0881226\tbest: 0.0881226 (2300)\ttotal: 1m 24s\tremaining: 1m 6s\n",
            "2320:\tlearn: 0.0491701\ttest: 0.0881195\tbest: 0.0881147 (2303)\ttotal: 1m 25s\tremaining: 1m 5s\n",
            "2340:\tlearn: 0.0489092\ttest: 0.0881136\tbest: 0.0881072 (2332)\ttotal: 1m 26s\tremaining: 1m 4s\n",
            "2360:\tlearn: 0.0486832\ttest: 0.0880689\tbest: 0.0880689 (2360)\ttotal: 1m 27s\tremaining: 1m 4s\n",
            "2380:\tlearn: 0.0484357\ttest: 0.0880623\tbest: 0.0880529 (2364)\ttotal: 1m 27s\tremaining: 1m 3s\n",
            "2400:\tlearn: 0.0482399\ttest: 0.0880468\tbest: 0.0880315 (2392)\ttotal: 1m 28s\tremaining: 1m 2s\n",
            "2420:\tlearn: 0.0480069\ttest: 0.0880074\tbest: 0.0880074 (2420)\ttotal: 1m 29s\tremaining: 1m 1s\n",
            "2440:\tlearn: 0.0477843\ttest: 0.0879583\tbest: 0.0879583 (2440)\ttotal: 1m 30s\tremaining: 1m 1s\n",
            "2460:\tlearn: 0.0475487\ttest: 0.0879155\tbest: 0.0879155 (2460)\ttotal: 1m 30s\tremaining: 1m\n",
            "2480:\tlearn: 0.0473350\ttest: 0.0878891\tbest: 0.0878854 (2478)\ttotal: 1m 31s\tremaining: 59.8s\n",
            "2500:\tlearn: 0.0471390\ttest: 0.0878666\tbest: 0.0878646 (2499)\ttotal: 1m 32s\tremaining: 59.1s\n",
            "2520:\tlearn: 0.0469010\ttest: 0.0878885\tbest: 0.0878561 (2508)\ttotal: 1m 33s\tremaining: 58.4s\n",
            "2540:\tlearn: 0.0466564\ttest: 0.0878502\tbest: 0.0878502 (2540)\ttotal: 1m 33s\tremaining: 57.6s\n",
            "2560:\tlearn: 0.0463956\ttest: 0.0878381\tbest: 0.0878334 (2549)\ttotal: 1m 34s\tremaining: 56.9s\n",
            "2580:\tlearn: 0.0461474\ttest: 0.0877989\tbest: 0.0877989 (2580)\ttotal: 1m 35s\tremaining: 56.2s\n",
            "2600:\tlearn: 0.0459268\ttest: 0.0877649\tbest: 0.0877637 (2599)\ttotal: 1m 36s\tremaining: 55.4s\n",
            "2620:\tlearn: 0.0457236\ttest: 0.0877649\tbest: 0.0877512 (2605)\ttotal: 1m 36s\tremaining: 54.7s\n",
            "2640:\tlearn: 0.0454946\ttest: 0.0877327\tbest: 0.0877319 (2639)\ttotal: 1m 37s\tremaining: 54s\n",
            "2660:\tlearn: 0.0452200\ttest: 0.0876760\tbest: 0.0876694 (2655)\ttotal: 1m 38s\tremaining: 53.2s\n",
            "2680:\tlearn: 0.0450406\ttest: 0.0876544\tbest: 0.0876544 (2680)\ttotal: 1m 39s\tremaining: 52.5s\n",
            "2700:\tlearn: 0.0448120\ttest: 0.0876905\tbest: 0.0876544 (2680)\ttotal: 1m 39s\tremaining: 51.8s\n",
            "2720:\tlearn: 0.0446061\ttest: 0.0876815\tbest: 0.0876544 (2680)\ttotal: 1m 40s\tremaining: 51s\n",
            "bestTest = 0.08765439722\n",
            "bestIteration = 2680\n",
            "Shrink model to first 2681 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "\t0.9\t = Validation score   (roc_auc)\n",
            "\t104.7s\t = Training   runtime\n",
            "\t0.8s\t = Validation runtime\n",
            "\t74137.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 424.91s of the 424.90s of remaining time.\n",
            "\tFitting ExtraTreesGini with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.5 GB\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "\t0.8771\t = Validation score   (roc_auc)\n",
            "\t11.89s\t = Training   runtime\n",
            "\t1.37s\t = Validation runtime\n",
            "\t43106.7\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 411.30s of the 411.29s of remaining time.\n",
            "\tFitting ExtraTreesEntr with 'num_gpus': 1, 'num_cpus': 8\n",
            "\tFitting with cpus=8, gpus=1, mem=0.0/42.3 GB\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "\t0.88\t = Validation score   (roc_auc)\n",
            "\t10.84s\t = Training   runtime\n",
            "\t1.3s\t = Validation runtime\n",
            "\t45398.1\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 398.82s of the 398.81s of remaining time.\n",
            "\tFitting NeuralNetFastAI with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.5/42.3 GB\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 31/31 categorical features\n",
            "Using 393 cont features\n",
            "Automated batch size selection: 256\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3-4): 2 x Embedding(61, 16)\n",
            "    (5-7): 3 x Embedding(4, 3)\n",
            "    (8): Embedding(5, 4)\n",
            "    (9-14): 6 x Embedding(4, 3)\n",
            "    (15): Embedding(5, 4)\n",
            "    (16): Embedding(4, 3)\n",
            "    (17): Embedding(5, 4)\n",
            "    (18-20): 3 x Embedding(4, 3)\n",
            "    (21): Embedding(71, 17)\n",
            "    (22): Embedding(105, 22)\n",
            "    (23): Embedding(90, 20)\n",
            "    (24): Embedding(6, 4)\n",
            "    (25-29): 5 x Embedding(4, 3)\n",
            "    (30): Embedding(607, 58)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(393, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): LinBnDrop(\n",
            "      (0): Linear(in_features=624, out_features=200, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): LinBnDrop(\n",
            "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): LinBnDrop(\n",
            "      (0): Linear(in_features=100, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Automated epochs selection: training for 30 epoch(s). Estimated time budget use 199.13 / 395.36 sec\n",
            "Better model found at epoch 0 with valid_loss value: 0.23255150020122528.\n",
            "Better model found at epoch 1 with valid_loss value: 0.12507060170173645.\n",
            "Better model found at epoch 2 with valid_loss value: 0.12104953080415726.\n",
            "Better model found at epoch 3 with valid_loss value: 0.11818386614322662.\n",
            "Better model found at epoch 8 with valid_loss value: 0.11801112443208694.\n",
            "No improvement since epoch 8: early stopping\n",
            "Model validation metrics: 0.11801112443208694\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "\t0.8388\t = Validation score   (roc_auc)\n",
            "\t127.08s\t = Training   runtime\n",
            "\t2.12s\t = Validation runtime\n",
            "\t27791.3\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: XGBoost ... Training model for up to 269.53s of the 269.52s of remaining time.\n",
            "\tFitting XGBoost with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.3/42.1 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.13363\n",
            "[50]\tvalidation_0-logloss:0.09315\n",
            "[100]\tvalidation_0-logloss:0.09009\n",
            "[150]\tvalidation_0-logloss:0.08843\n",
            "[200]\tvalidation_0-logloss:0.08729\n",
            "[250]\tvalidation_0-logloss:0.08703\n",
            "[300]\tvalidation_0-logloss:0.08702\n",
            "[350]\tvalidation_0-logloss:0.08693\n",
            "[394]\tvalidation_0-logloss:0.08715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [01:02:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "\t0.9026\t = Validation score   (roc_auc)\n",
            "\t6.61s\t = Training   runtime\n",
            "\t1.8s\t = Validation runtime\n",
            "\t32895.2\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 261.08s of the 261.07s of remaining time.\n",
            "\tFitting NeuralNetTorch with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=0.7/42.1 GB\n",
            "Tabular Neural Network treats features as the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"TransactionID\",\n",
            "        \"TransactionDT\",\n",
            "        \"card1\",\n",
            "        \"card2\",\n",
            "        \"addr1\",\n",
            "        \"D9\",\n",
            "        \"D15\",\n",
            "        \"V4\",\n",
            "        \"V5\",\n",
            "        \"V10\",\n",
            "        \"V11\",\n",
            "        \"V12\",\n",
            "        \"V13\",\n",
            "        \"V19\",\n",
            "        \"V20\",\n",
            "        \"V29\",\n",
            "        \"V35\",\n",
            "        \"V36\",\n",
            "        \"V48\",\n",
            "        \"V53\",\n",
            "        \"V54\",\n",
            "        \"V61\",\n",
            "        \"V62\",\n",
            "        \"V69\",\n",
            "        \"V75\",\n",
            "        \"V76\",\n",
            "        \"V82\",\n",
            "        \"V83\",\n",
            "        \"V90\",\n",
            "        \"V194\",\n",
            "        \"id_07\",\n",
            "        \"id_08\",\n",
            "        \"id_17\",\n",
            "        \"id_19\",\n",
            "        \"id_20\",\n",
            "        \"id_25\",\n",
            "        \"id_26\",\n",
            "        \"id_32\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"TransactionAmt\",\n",
            "        \"card3\",\n",
            "        \"card5\",\n",
            "        \"addr2\",\n",
            "        \"dist1\",\n",
            "        \"dist2\",\n",
            "        \"C1\",\n",
            "        \"C2\",\n",
            "        \"C3\",\n",
            "        \"C4\",\n",
            "        \"C5\",\n",
            "        \"C6\",\n",
            "        \"C7\",\n",
            "        \"C8\",\n",
            "        \"C9\",\n",
            "        \"C10\",\n",
            "        \"C11\",\n",
            "        \"C12\",\n",
            "        \"C13\",\n",
            "        \"C14\",\n",
            "        \"D1\",\n",
            "        \"D2\",\n",
            "        \"D3\",\n",
            "        \"D4\",\n",
            "        \"D5\",\n",
            "        \"D6\",\n",
            "        \"D7\",\n",
            "        \"D8\",\n",
            "        \"D10\",\n",
            "        \"D11\",\n",
            "        \"D12\",\n",
            "        \"D13\",\n",
            "        \"D14\",\n",
            "        \"V1\",\n",
            "        \"V2\",\n",
            "        \"V3\",\n",
            "        \"V6\",\n",
            "        \"V7\",\n",
            "        \"V8\",\n",
            "        \"V9\",\n",
            "        \"V14\",\n",
            "        \"V15\",\n",
            "        \"V16\",\n",
            "        \"V17\",\n",
            "        \"V18\",\n",
            "        \"V21\",\n",
            "        \"V22\",\n",
            "        \"V23\",\n",
            "        \"V24\",\n",
            "        \"V25\",\n",
            "        \"V26\",\n",
            "        \"V27\",\n",
            "        \"V28\",\n",
            "        \"V30\",\n",
            "        \"V31\",\n",
            "        \"V32\",\n",
            "        \"V33\",\n",
            "        \"V34\",\n",
            "        \"V37\",\n",
            "        \"V38\",\n",
            "        \"V39\",\n",
            "        \"V40\",\n",
            "        \"V41\",\n",
            "        \"V42\",\n",
            "        \"V43\",\n",
            "        \"V44\",\n",
            "        \"V45\",\n",
            "        \"V46\",\n",
            "        \"V47\",\n",
            "        \"V49\",\n",
            "        \"V50\",\n",
            "        \"V51\",\n",
            "        \"V52\",\n",
            "        \"V55\",\n",
            "        \"V56\",\n",
            "        \"V57\",\n",
            "        \"V58\",\n",
            "        \"V59\",\n",
            "        \"V60\",\n",
            "        \"V63\",\n",
            "        \"V64\",\n",
            "        \"V65\",\n",
            "        \"V66\",\n",
            "        \"V67\",\n",
            "        \"V68\",\n",
            "        \"V70\",\n",
            "        \"V71\",\n",
            "        \"V72\",\n",
            "        \"V73\",\n",
            "        \"V74\",\n",
            "        \"V77\",\n",
            "        \"V78\",\n",
            "        \"V79\",\n",
            "        \"V80\",\n",
            "        \"V81\",\n",
            "        \"V84\",\n",
            "        \"V85\",\n",
            "        \"V86\",\n",
            "        \"V87\",\n",
            "        \"V88\",\n",
            "        \"V89\",\n",
            "        \"V91\",\n",
            "        \"V92\",\n",
            "        \"V93\",\n",
            "        \"V94\",\n",
            "        \"V95\",\n",
            "        \"V96\",\n",
            "        \"V97\",\n",
            "        \"V98\",\n",
            "        \"V99\",\n",
            "        \"V100\",\n",
            "        \"V101\",\n",
            "        \"V102\",\n",
            "        \"V103\",\n",
            "        \"V104\",\n",
            "        \"V105\",\n",
            "        \"V106\",\n",
            "        \"V107\",\n",
            "        \"V108\",\n",
            "        \"V109\",\n",
            "        \"V110\",\n",
            "        \"V111\",\n",
            "        \"V112\",\n",
            "        \"V114\",\n",
            "        \"V115\",\n",
            "        \"V116\",\n",
            "        \"V117\",\n",
            "        \"V118\",\n",
            "        \"V120\",\n",
            "        \"V121\",\n",
            "        \"V122\",\n",
            "        \"V123\",\n",
            "        \"V124\",\n",
            "        \"V125\",\n",
            "        \"V126\",\n",
            "        \"V127\",\n",
            "        \"V128\",\n",
            "        \"V129\",\n",
            "        \"V130\",\n",
            "        \"V131\",\n",
            "        \"V132\",\n",
            "        \"V133\",\n",
            "        \"V134\",\n",
            "        \"V135\",\n",
            "        \"V136\",\n",
            "        \"V137\",\n",
            "        \"V138\",\n",
            "        \"V139\",\n",
            "        \"V140\",\n",
            "        \"V141\",\n",
            "        \"V142\",\n",
            "        \"V143\",\n",
            "        \"V144\",\n",
            "        \"V145\",\n",
            "        \"V146\",\n",
            "        \"V148\",\n",
            "        \"V150\",\n",
            "        \"V151\",\n",
            "        \"V152\",\n",
            "        \"V153\",\n",
            "        \"V155\",\n",
            "        \"V157\",\n",
            "        \"V158\",\n",
            "        \"V159\",\n",
            "        \"V160\",\n",
            "        \"V161\",\n",
            "        \"V162\",\n",
            "        \"V163\",\n",
            "        \"V164\",\n",
            "        \"V165\",\n",
            "        \"V166\",\n",
            "        \"V167\",\n",
            "        \"V168\",\n",
            "        \"V169\",\n",
            "        \"V170\",\n",
            "        \"V171\",\n",
            "        \"V172\",\n",
            "        \"V173\",\n",
            "        \"V174\",\n",
            "        \"V175\",\n",
            "        \"V176\",\n",
            "        \"V177\",\n",
            "        \"V178\",\n",
            "        \"V179\",\n",
            "        \"V180\",\n",
            "        \"V181\",\n",
            "        \"V182\",\n",
            "        \"V183\",\n",
            "        \"V184\",\n",
            "        \"V185\",\n",
            "        \"V186\",\n",
            "        \"V187\",\n",
            "        \"V188\",\n",
            "        \"V189\",\n",
            "        \"V190\",\n",
            "        \"V191\",\n",
            "        \"V192\",\n",
            "        \"V193\",\n",
            "        \"V195\",\n",
            "        \"V196\",\n",
            "        \"V197\",\n",
            "        \"V199\",\n",
            "        \"V200\",\n",
            "        \"V201\",\n",
            "        \"V202\",\n",
            "        \"V203\",\n",
            "        \"V204\",\n",
            "        \"V205\",\n",
            "        \"V206\",\n",
            "        \"V207\",\n",
            "        \"V208\",\n",
            "        \"V209\",\n",
            "        \"V210\",\n",
            "        \"V211\",\n",
            "        \"V212\",\n",
            "        \"V213\",\n",
            "        \"V214\",\n",
            "        \"V215\",\n",
            "        \"V216\",\n",
            "        \"V217\",\n",
            "        \"V218\",\n",
            "        \"V219\",\n",
            "        \"V220\",\n",
            "        \"V221\",\n",
            "        \"V222\",\n",
            "        \"V223\",\n",
            "        \"V224\",\n",
            "        \"V225\",\n",
            "        \"V226\",\n",
            "        \"V227\",\n",
            "        \"V228\",\n",
            "        \"V229\",\n",
            "        \"V230\",\n",
            "        \"V231\",\n",
            "        \"V232\",\n",
            "        \"V233\",\n",
            "        \"V234\",\n",
            "        \"V235\",\n",
            "        \"V236\",\n",
            "        \"V237\",\n",
            "        \"V238\",\n",
            "        \"V239\",\n",
            "        \"V240\",\n",
            "        \"V242\",\n",
            "        \"V243\",\n",
            "        \"V244\",\n",
            "        \"V245\",\n",
            "        \"V246\",\n",
            "        \"V247\",\n",
            "        \"V248\",\n",
            "        \"V249\",\n",
            "        \"V250\",\n",
            "        \"V251\",\n",
            "        \"V252\",\n",
            "        \"V253\",\n",
            "        \"V254\",\n",
            "        \"V255\",\n",
            "        \"V256\",\n",
            "        \"V257\",\n",
            "        \"V258\",\n",
            "        \"V259\",\n",
            "        \"V260\",\n",
            "        \"V261\",\n",
            "        \"V262\",\n",
            "        \"V263\",\n",
            "        \"V264\",\n",
            "        \"V265\",\n",
            "        \"V266\",\n",
            "        \"V267\",\n",
            "        \"V268\",\n",
            "        \"V269\",\n",
            "        \"V270\",\n",
            "        \"V271\",\n",
            "        \"V272\",\n",
            "        \"V273\",\n",
            "        \"V274\",\n",
            "        \"V275\",\n",
            "        \"V276\",\n",
            "        \"V277\",\n",
            "        \"V278\",\n",
            "        \"V279\",\n",
            "        \"V280\",\n",
            "        \"V281\",\n",
            "        \"V282\",\n",
            "        \"V283\",\n",
            "        \"V284\",\n",
            "        \"V285\",\n",
            "        \"V286\",\n",
            "        \"V287\",\n",
            "        \"V288\",\n",
            "        \"V289\",\n",
            "        \"V290\",\n",
            "        \"V291\",\n",
            "        \"V292\",\n",
            "        \"V293\",\n",
            "        \"V294\",\n",
            "        \"V295\",\n",
            "        \"V296\",\n",
            "        \"V297\",\n",
            "        \"V298\",\n",
            "        \"V299\",\n",
            "        \"V300\",\n",
            "        \"V301\",\n",
            "        \"V302\",\n",
            "        \"V303\",\n",
            "        \"V304\",\n",
            "        \"V306\",\n",
            "        \"V307\",\n",
            "        \"V308\",\n",
            "        \"V309\",\n",
            "        \"V310\",\n",
            "        \"V311\",\n",
            "        \"V312\",\n",
            "        \"V313\",\n",
            "        \"V314\",\n",
            "        \"V315\",\n",
            "        \"V316\",\n",
            "        \"V317\",\n",
            "        \"V318\",\n",
            "        \"V319\",\n",
            "        \"V320\",\n",
            "        \"V321\",\n",
            "        \"V322\",\n",
            "        \"V323\",\n",
            "        \"V324\",\n",
            "        \"V325\",\n",
            "        \"V326\",\n",
            "        \"V327\",\n",
            "        \"V328\",\n",
            "        \"V329\",\n",
            "        \"V330\",\n",
            "        \"V331\",\n",
            "        \"V332\",\n",
            "        \"V333\",\n",
            "        \"V334\",\n",
            "        \"V335\",\n",
            "        \"V336\",\n",
            "        \"V337\",\n",
            "        \"V338\",\n",
            "        \"V339\",\n",
            "        \"id_01\",\n",
            "        \"id_02\",\n",
            "        \"id_03\",\n",
            "        \"id_04\",\n",
            "        \"id_05\",\n",
            "        \"id_06\",\n",
            "        \"id_09\",\n",
            "        \"id_10\",\n",
            "        \"id_11\",\n",
            "        \"id_13\",\n",
            "        \"id_14\",\n",
            "        \"id_18\",\n",
            "        \"id_21\",\n",
            "        \"id_22\",\n",
            "        \"id_24\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"M1\",\n",
            "        \"M2\",\n",
            "        \"M3\",\n",
            "        \"M5\",\n",
            "        \"M6\",\n",
            "        \"M7\",\n",
            "        \"M8\",\n",
            "        \"M9\",\n",
            "        \"id_12\",\n",
            "        \"id_16\",\n",
            "        \"id_27\",\n",
            "        \"id_28\",\n",
            "        \"id_29\",\n",
            "        \"id_35\",\n",
            "        \"id_36\",\n",
            "        \"id_37\",\n",
            "        \"id_38\",\n",
            "        \"DeviceType\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"ProductCD\",\n",
            "        \"card4\",\n",
            "        \"card6\",\n",
            "        \"P_emaildomain\",\n",
            "        \"R_emaildomain\",\n",
            "        \"M4\",\n",
            "        \"id_15\",\n",
            "        \"id_23\",\n",
            "        \"id_30\",\n",
            "        \"id_31\",\n",
            "        \"id_33\",\n",
            "        \"id_34\",\n",
            "        \"DeviceInfo\"\n",
            "    ],\n",
            "    \"language\": [],\n",
            "    \"bool\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for TabularNeuralNetTorchModel has: 50000 examples, 424 features (411 vector, 13 embedding)\n",
            "Training on GPU (CUDA)\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (embed_blocks): ModuleList(\n",
            "    (0-2): 3 x Embedding(6, 4)\n",
            "    (3): Embedding(61, 15)\n",
            "    (4): Embedding(60, 15)\n",
            "    (5-7): 3 x Embedding(5, 3)\n",
            "    (8): Embedding(72, 17)\n",
            "    (9): Embedding(102, 21)\n",
            "    (10): Embedding(82, 18)\n",
            "    (11): Embedding(6, 4)\n",
            "    (12): Embedding(102, 21)\n",
            "  )\n",
            "  (main_block): Sequential(\n",
            "    (0): Linear(in_features=579, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (10): ReLU()\n",
            "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Training tabular neural network for up to 1000 epochs...\n",
            "Epoch 1 (Update 390).\tTrain loss: 0.1321, Val roc_auc: 0.8316, Best Epoch: 1\n",
            "Epoch 2 (Update 780).\tTrain loss: 0.1112, Val roc_auc: 0.851, Best Epoch: 2\n",
            "Epoch 3 (Update 1170).\tTrain loss: 0.1062, Val roc_auc: 0.8589, Best Epoch: 3\n",
            "Epoch 4 (Update 1560).\tTrain loss: 0.1026, Val roc_auc: 0.86, Best Epoch: 4\n",
            "Epoch 5 (Update 1950).\tTrain loss: 0.1012, Val roc_auc: 0.8657, Best Epoch: 5\n",
            "Epoch 6 (Update 2340).\tTrain loss: 0.1, Val roc_auc: 0.8671, Best Epoch: 6\n",
            "Epoch 7 (Update 2730).\tTrain loss: 0.0983, Val roc_auc: 0.8653, Best Epoch: 6\n",
            "Epoch 8 (Update 3120).\tTrain loss: 0.0969, Val roc_auc: 0.8678, Best Epoch: 8\n",
            "Epoch 9 (Update 3510).\tTrain loss: 0.0953, Val roc_auc: 0.8664, Best Epoch: 8\n",
            "Epoch 10 (Update 3900).\tTrain loss: 0.0942, Val roc_auc: 0.8693, Best Epoch: 10\n",
            "Epoch 11 (Update 4290).\tTrain loss: 0.0938, Val roc_auc: 0.8644, Best Epoch: 10\n",
            "Epoch 12 (Update 4680).\tTrain loss: 0.0928, Val roc_auc: 0.8689, Best Epoch: 10\n",
            "Epoch 13 (Update 5070).\tTrain loss: 0.092, Val roc_auc: 0.8682, Best Epoch: 10\n",
            "Epoch 14 (Update 5460).\tTrain loss: 0.0911, Val roc_auc: 0.8694, Best Epoch: 14\n",
            "Epoch 15 (Update 5850).\tTrain loss: 0.0899, Val roc_auc: 0.8669, Best Epoch: 14\n",
            "Epoch 16 (Update 6240).\tTrain loss: 0.0893, Val roc_auc: 0.8712, Best Epoch: 16\n",
            "Epoch 17 (Update 6630).\tTrain loss: 0.0886, Val roc_auc: 0.866, Best Epoch: 16\n",
            "Epoch 18 (Update 7020).\tTrain loss: 0.0884, Val roc_auc: 0.8693, Best Epoch: 16\n",
            "Epoch 19 (Update 7410).\tTrain loss: 0.0871, Val roc_auc: 0.8625, Best Epoch: 16\n",
            "Epoch 20 (Update 7800).\tTrain loss: 0.0866, Val roc_auc: 0.8661, Best Epoch: 16\n",
            "Epoch 21 (Update 8190).\tTrain loss: 0.0866, Val roc_auc: 0.8617, Best Epoch: 16\n",
            "Epoch 22 (Update 8580).\tTrain loss: 0.0848, Val roc_auc: 0.865, Best Epoch: 16\n",
            "Epoch 23 (Update 8970).\tTrain loss: 0.0844, Val roc_auc: 0.8649, Best Epoch: 16\n",
            "Epoch 24 (Update 9360).\tTrain loss: 0.0841, Val roc_auc: 0.861, Best Epoch: 16\n",
            "Epoch 25 (Update 9750).\tTrain loss: 0.0833, Val roc_auc: 0.8617, Best Epoch: 16\n",
            "Epoch 26 (Update 10140).\tTrain loss: 0.0814, Val roc_auc: 0.8571, Best Epoch: 16\n",
            "Epoch 27 (Update 10530).\tTrain loss: 0.0828, Val roc_auc: 0.8639, Best Epoch: 16\n",
            "Epoch 28 (Update 10920).\tTrain loss: 0.0805, Val roc_auc: 0.8645, Best Epoch: 16\n",
            "Epoch 29 (Update 11310).\tTrain loss: 0.0811, Val roc_auc: 0.8468, Best Epoch: 16\n",
            "Epoch 30 (Update 11700).\tTrain loss: 0.0807, Val roc_auc: 0.858, Best Epoch: 16\n",
            "Epoch 31 (Update 12090).\tTrain loss: 0.0816, Val roc_auc: 0.8644, Best Epoch: 16\n",
            "Epoch 32 (Update 12480).\tTrain loss: 0.0793, Val roc_auc: 0.8526, Best Epoch: 16\n",
            "Epoch 33 (Update 12870).\tTrain loss: 0.0791, Val roc_auc: 0.8463, Best Epoch: 16\n",
            "Epoch 34 (Update 13260).\tTrain loss: 0.0778, Val roc_auc: 0.8549, Best Epoch: 16\n",
            "Epoch 35 (Update 13650).\tTrain loss: 0.0774, Val roc_auc: 0.835, Best Epoch: 16\n",
            "Epoch 36 (Update 14040).\tTrain loss: 0.0784, Val roc_auc: 0.8539, Best Epoch: 16\n",
            "Epoch 37 (Update 14430).\tTrain loss: 0.0761, Val roc_auc: 0.8446, Best Epoch: 16\n",
            "Epoch 38 (Update 14820).\tTrain loss: 0.0772, Val roc_auc: 0.8406, Best Epoch: 16\n",
            "Epoch 39 (Update 15210).\tTrain loss: 0.0756, Val roc_auc: 0.8523, Best Epoch: 16\n",
            "Epoch 40 (Update 15600).\tTrain loss: 0.0755, Val roc_auc: 0.8376, Best Epoch: 16\n",
            "Epoch 41 (Update 15990).\tTrain loss: 0.075, Val roc_auc: 0.8544, Best Epoch: 16\n",
            "Epoch 42 (Update 16380).\tTrain loss: 0.0736, Val roc_auc: 0.8353, Best Epoch: 16\n",
            "Epoch 43 (Update 16770).\tTrain loss: 0.0749, Val roc_auc: 0.836, Best Epoch: 16\n",
            "Epoch 44 (Update 17160).\tTrain loss: 0.0737, Val roc_auc: 0.8354, Best Epoch: 16\n",
            "Best model found on Epoch 16 (Update 6240). Val roc_auc: 0.8712098642597333\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "\t0.8712\t = Validation score   (roc_auc)\n",
            "\t112.24s\t = Training   runtime\n",
            "\t2.89s\t = Validation runtime\n",
            "\t20455.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMLarge ... Training model for up to 145.92s of the 145.91s of remaining time.\n",
            "\tFitting LightGBMLarge with 'num_gpus': 1, 'num_cpus': 4\n",
            "\tFitting with cpus=4, gpus=1, mem=1.1/42.2 GB\n",
            "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'device': 'gpu'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50]\tvalid_set's binary_logloss: 0.0986407\n",
            "[100]\tvalid_set's binary_logloss: 0.0913516\n",
            "[150]\tvalid_set's binary_logloss: 0.0891788\n",
            "[200]\tvalid_set's binary_logloss: 0.089345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "\t0.9055\t = Validation score   (roc_auc)\n",
            "\t14.97s\t = Training   runtime\n",
            "\t0.96s\t = Validation runtime\n",
            "\t61198.4\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/RandomForestEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/RandomForestGini/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/ExtraTreesGini/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/ExtraTreesEntr/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBMLarge/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/utils/attr/XGBoost/y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 129.85s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 1, 'num_cpus': 8\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 14\n",
            "Ensemble weights: \n",
            "[0.         0.35714286 0.         0.         0.21428571 0.\n",
            " 0.07142857 0.         0.14285714 0.         0.21428571]\n",
            "\t0.24s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBM': 0.357, 'CatBoost': 0.214, 'LightGBMLarge': 0.214, 'XGBoost': 0.143, 'ExtraTreesEntr': 0.071}\n",
            "\t0.9136\t = Validation score   (roc_auc)\n",
            "\t2.37s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t10243.0\t = Inference  throughput (rows/s | 59054 batch size)\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 473.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10243.0 rows/s (59054 batch size)\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels\")\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/RandomForestGini/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/RandomForestEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesGini/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetFastAI/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetFastAI/model-internals.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/NeuralNetTorch/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                  model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2   0.913558     roc_auc       5.765288  147.908514                0.009449           2.372238            2       True         12\n",
            "1              LightGBM   0.906887     roc_auc       0.898313    8.423219                0.898313           8.423219            1       True          2\n",
            "2         LightGBMLarge   0.905451     roc_auc       0.964960   14.969553                0.964960          14.969553            1       True         11\n",
            "3               XGBoost   0.902599     roc_auc       1.795214    6.608451                1.795214           6.608451            1       True          9\n",
            "4            LightGBMXT   0.901515     roc_auc       1.791793   19.399046                1.791793          19.399046            1       True          1\n",
            "5              CatBoost   0.899965     roc_auc       0.796548  104.696479                0.796548         104.696479            1       True          5\n",
            "6      RandomForestEntr   0.883320     roc_auc       1.163429   11.579385                1.163429          11.579385            1       True          4\n",
            "7      RandomForestGini   0.880236     roc_auc       1.390194   15.376461                1.390194          15.376461            1       True          3\n",
            "8        ExtraTreesEntr   0.879973     roc_auc       1.300804   10.838575                1.300804          10.838575            1       True          7\n",
            "9        ExtraTreesGini   0.877093     roc_auc       1.369949   11.891398                1.369949          11.891398            1       True          6\n",
            "10       NeuralNetTorch   0.871210     roc_auc       2.886964  112.236289                2.886964         112.236289            1       True         10\n",
            "11      NeuralNetFastAI   0.838762     roc_auc       2.124910  127.078120                2.124910         127.078120            1       True          8\n",
            "Number of models trained: 12\n",
            "Types of models trained:\n",
            "{'LGBModel', 'XGBoostModel', 'WeightedEnsembleModel', 'RFModel', 'XTModel', 'CatBoostModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel'}\n",
            "Bagging used: False \n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 391 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "782_DHP4LEkR",
        "outputId": "664b57b0-7a27-4669-85b9-db772de73b18"
      },
      "id": "782_DHP4LEkR",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  model  score_val eval_metric  pred_time_val    fit_time  \\\n",
              "0   WeightedEnsemble_L2   0.913558     roc_auc       5.765288  147.908514   \n",
              "1              LightGBM   0.906887     roc_auc       0.898313    8.423219   \n",
              "2         LightGBMLarge   0.905451     roc_auc       0.964960   14.969553   \n",
              "3               XGBoost   0.902599     roc_auc       1.795214    6.608451   \n",
              "4            LightGBMXT   0.901515     roc_auc       1.791793   19.399046   \n",
              "5              CatBoost   0.899965     roc_auc       0.796548  104.696479   \n",
              "6      RandomForestEntr   0.883320     roc_auc       1.163429   11.579385   \n",
              "7      RandomForestGini   0.880236     roc_auc       1.390194   15.376461   \n",
              "8        ExtraTreesEntr   0.879973     roc_auc       1.300804   10.838575   \n",
              "9        ExtraTreesGini   0.877093     roc_auc       1.369949   11.891398   \n",
              "10       NeuralNetTorch   0.871210     roc_auc       2.886964  112.236289   \n",
              "11      NeuralNetFastAI   0.838762     roc_auc       2.124910  127.078120   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.009449           2.372238            2       True   \n",
              "1                 0.898313           8.423219            1       True   \n",
              "2                 0.964960          14.969553            1       True   \n",
              "3                 1.795214           6.608451            1       True   \n",
              "4                 1.791793          19.399046            1       True   \n",
              "5                 0.796548         104.696479            1       True   \n",
              "6                 1.163429          11.579385            1       True   \n",
              "7                 1.390194          15.376461            1       True   \n",
              "8                 1.300804          10.838575            1       True   \n",
              "9                 1.369949          11.891398            1       True   \n",
              "10                2.886964         112.236289            1       True   \n",
              "11                2.124910         127.078120            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          12  \n",
              "1           2  \n",
              "2          11  \n",
              "3           9  \n",
              "4           1  \n",
              "5           5  \n",
              "6           4  \n",
              "7           3  \n",
              "8           7  \n",
              "9           6  \n",
              "10         10  \n",
              "11          8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3273368c-a2a2-404d-a325-cda615c3b219\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.913558</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>5.765288</td>\n",
              "      <td>147.908514</td>\n",
              "      <td>0.009449</td>\n",
              "      <td>2.372238</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.906887</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.898313</td>\n",
              "      <td>8.423219</td>\n",
              "      <td>0.898313</td>\n",
              "      <td>8.423219</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.905451</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.964960</td>\n",
              "      <td>14.969553</td>\n",
              "      <td>0.964960</td>\n",
              "      <td>14.969553</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.902599</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.795214</td>\n",
              "      <td>6.608451</td>\n",
              "      <td>1.795214</td>\n",
              "      <td>6.608451</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.901515</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.791793</td>\n",
              "      <td>19.399046</td>\n",
              "      <td>1.791793</td>\n",
              "      <td>19.399046</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.899965</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.796548</td>\n",
              "      <td>104.696479</td>\n",
              "      <td>0.796548</td>\n",
              "      <td>104.696479</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.883320</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.163429</td>\n",
              "      <td>11.579385</td>\n",
              "      <td>1.163429</td>\n",
              "      <td>11.579385</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.880236</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.390194</td>\n",
              "      <td>15.376461</td>\n",
              "      <td>1.390194</td>\n",
              "      <td>15.376461</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.879973</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.300804</td>\n",
              "      <td>10.838575</td>\n",
              "      <td>1.300804</td>\n",
              "      <td>10.838575</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.877093</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.369949</td>\n",
              "      <td>11.891398</td>\n",
              "      <td>1.369949</td>\n",
              "      <td>11.891398</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.871210</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>2.886964</td>\n",
              "      <td>112.236289</td>\n",
              "      <td>2.886964</td>\n",
              "      <td>112.236289</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.838762</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>2.124910</td>\n",
              "      <td>127.078120</td>\n",
              "      <td>2.124910</td>\n",
              "      <td>127.078120</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3273368c-a2a2-404d-a325-cda615c3b219')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3273368c-a2a2-404d-a325-cda615c3b219 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3273368c-a2a2-404d-a325-cda615c3b219');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4fd2cdf3-875d-4ce0-8f94-6aa374f21d0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4fd2cdf3-875d-4ce0-8f94-6aa374f21d0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4fd2cdf3-875d-4ce0-8f94-6aa374f21d0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"NeuralNetTorch\",\n          \"ExtraTreesGini\",\n          \"WeightedEnsemble_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02094055977792249,\n        \"min\": 0.8387616258065165,\n        \"max\": 0.9135576919744861,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.8712098642597333,\n          0.8770933526808279,\n          0.9135576919744861\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roc_auc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3651564273218582,\n        \"min\": 0.7965478897094727,\n        \"max\": 5.765287637710571,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.8869636058807373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.44961221620827,\n        \"min\": 6.608450889587402,\n        \"max\": 147.9085144996643,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          112.2362892627716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7288791965207948,\n        \"min\": 0.009449005126953125,\n        \"max\": 2.8869636058807373,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.8869636058807373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47.213578891648986,\n        \"min\": 2.3722381591796875,\n        \"max\": 127.07812023162842,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          112.2362892627716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "y_true = test_data[label].astype(int)\n",
        "y_pred = predictor.predict(test_data.drop(columns=[label]),model='LightGBM')\n",
        "AUC = roc_auc_score(y_true, y_pred)\n",
        "print(AUC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmwQfUAoLb22",
        "outputId": "fc981946-408e-4948-8626-6f1446c54b54"
      },
      "id": "tmwQfUAoLb22",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6999806413211191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.value_counts(),y_true.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqnEoUy5NKZ4",
        "outputId": "e2a3aa52-bcbf-4d69-8f43-a565347e6997"
      },
      "id": "sqnEoUy5NKZ4",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(isFraud\n",
              " 0    58105\n",
              " 1      949\n",
              " Name: count, dtype: int64,\n",
              " isFraud\n",
              " 0    56987\n",
              " 1     2067\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M0CW-HNyq3iS",
        "outputId": "7d194bd1-e4a3-4b40-e574-e8b4e020e4d0"
      },
      "id": "M0CW-HNyq3iS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "These features in provided data are not utilized by the predictor and will be ignored: ['V113', 'V119', 'V147', 'V149', 'V154', 'V156', 'V198', 'V241']\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Computing feature importance via permutation shuffling for 425 features using 5000 rows with 5 shuffle sets...\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\t1696.72s\t= Expected runtime (339.34s per shuffle set)\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\t1077.33s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                importance    stddev   p_value  n  p99_high   p99_low\n",
              "C13               0.008521  0.001359  0.000075  5  0.011318  0.005724\n",
              "C1                0.008518  0.002146  0.000446  5  0.012937  0.004098\n",
              "TransactionAmt    0.007212  0.004616  0.012523  5  0.016717 -0.002293\n",
              "card6             0.006791  0.002619  0.002199  5  0.012183  0.001399\n",
              "C11               0.006419  0.002103  0.001205  5  0.010749  0.002089\n",
              "...                    ...       ...       ... ..       ...       ...\n",
              "V52              -0.000390  0.000660  0.871831  5  0.000968 -0.001749\n",
              "V51              -0.000462  0.000435  0.961643  5  0.000435 -0.001358\n",
              "D5               -0.000482  0.000432  0.966479  5  0.000407 -0.001372\n",
              "V258             -0.000498  0.001128  0.810192  5  0.001825 -0.002820\n",
              "V65              -0.000740  0.001552  0.826709  5  0.002456 -0.003935\n",
              "\n",
              "[425 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-823afddc-ab14-4e17-a61e-384a41743df9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C13</th>\n",
              "      <td>0.008521</td>\n",
              "      <td>0.001359</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>5</td>\n",
              "      <td>0.011318</td>\n",
              "      <td>0.005724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1</th>\n",
              "      <td>0.008518</td>\n",
              "      <td>0.002146</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012937</td>\n",
              "      <td>0.004098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.007212</td>\n",
              "      <td>0.004616</td>\n",
              "      <td>0.012523</td>\n",
              "      <td>5</td>\n",
              "      <td>0.016717</td>\n",
              "      <td>-0.002293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card6</th>\n",
              "      <td>0.006791</td>\n",
              "      <td>0.002619</td>\n",
              "      <td>0.002199</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012183</td>\n",
              "      <td>0.001399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C11</th>\n",
              "      <td>0.006419</td>\n",
              "      <td>0.002103</td>\n",
              "      <td>0.001205</td>\n",
              "      <td>5</td>\n",
              "      <td>0.010749</td>\n",
              "      <td>0.002089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V52</th>\n",
              "      <td>-0.000390</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>0.871831</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000968</td>\n",
              "      <td>-0.001749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V51</th>\n",
              "      <td>-0.000462</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.961643</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>-0.001358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D5</th>\n",
              "      <td>-0.000482</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.966479</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>-0.001372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V258</th>\n",
              "      <td>-0.000498</td>\n",
              "      <td>0.001128</td>\n",
              "      <td>0.810192</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001825</td>\n",
              "      <td>-0.002820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V65</th>\n",
              "      <td>-0.000740</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.826709</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>-0.003935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>425 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-823afddc-ab14-4e17-a61e-384a41743df9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-823afddc-ab14-4e17-a61e-384a41743df9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-823afddc-ab14-4e17-a61e-384a41743df9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d9bd90a-a3a6-4016-8204-6f44a7f37b78\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d9bd90a-a3a6-4016-8204-6f44a7f37b78')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d9bd90a-a3a6-4016-8204-6f44a7f37b78 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 425,\n  \"fields\": [\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009894880244534904,\n        \"min\": -0.0007397166856890847,\n        \"max\": 0.008520700344363984,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          8.522843996483509e-05,\n          -1.645603058517686e-05,\n          5.596511573562335e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stddev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005121577696261699,\n        \"min\": 0.0,\n        \"max\": 0.0046162806063738925,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.00010488648116243812,\n          0.00010613967742934467,\n          0.0003608297374849713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2994475155527214,\n        \"min\": 1.634511564048646e-05,\n        \"max\": 0.9927506399846172,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.07168969508439679,\n          0.6268502878917044,\n          0.37310306764217305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018887329958601933,\n        \"min\": 0.0,\n        \"max\": 0.016717026088059188,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          0.00030119115436352416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p99_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007842000282485597,\n        \"min\": -0.005025585430949625,\n        \"max\": 0.005723524333170176,\n        \"num_unique_values\": 422,\n        \"samples\": [\n          -0.000130734274433854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "id": "oQgwNpCNa1ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9910e0e0-78e5-4326-bc0b-d74b4d72a315"
      },
      "id": "oQgwNpCNa1ia",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "id": "e3jdxESRa3Kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45e6c8f-aecf-47a0-a8dd-ee2fec9f25bc"
      },
      "id": "e3jdxESRa3Kt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "id": "Vez_9GNza4vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c2ae64-cba4-47ab-cc81-0f10d4ab5288"
      },
      "id": "Vez_9GNza4vC",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/CatBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/ExtraTreesEntr/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBM/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/LightGBMLarge/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/XGBoost/model.pkl\n",
            "Loading: /content/drive/MyDrive/AutoGluon-Datasets/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "ot_fBRgJbCxN"
      },
      "id": "ot_fBRgJbCxN",
      "execution_count": 28,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}